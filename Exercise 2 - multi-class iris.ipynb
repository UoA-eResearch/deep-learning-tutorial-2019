{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 2 - multi-class iris.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UoA-eResearch/deep-learning-tutorial-2019/blob/master/Exercise%202%20-%20multi-class%20iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPQTvjnTzTqM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2: The Iris Dataset\n",
        "In this exercise we will create a neural network to classify 3 different types of Iris (Setosa, Versicolor and Virginica) based on their sepal length, sepal width, petal length and petal width.\n",
        "\n",
        "![Irises](http://dataaspirant.com/wp-content/uploads/2017/01/irises.png)\n",
        "\n",
        "This is a multi class classification problem. It is similar to the Pima Indian's binary classification exercise, but with three classes to predict instead of two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B9pUqCzTqO",
        "colab_type": "text"
      },
      "source": [
        "### Import dependencies\n",
        "Start by importing the dependencies we will need for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB8CJHppzTqP",
        "colab_type": "code",
        "outputId": "9e9cd859-2226-4df2-e119-47cb4868026f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcA6fnZKzTqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_acc_loss(history):\n",
        "    f, (ax1, ax2) = plt.subplots(2,1, figsize=(10,10))\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax1.plot(history.history['loss'])\n",
        "    ax1.plot(history.history['val_loss'])\n",
        "    ax1.set_title('model loss')\n",
        "    ax1.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax2.plot(history.history['acc'])\n",
        "    ax2.plot(history.history['val_acc'])\n",
        "    ax2.set_title('model accuracy')\n",
        "    ax2.set_xlabel('epoch')\n",
        "    ax2.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuDTA3s9zTqV",
        "colab_type": "text"
      },
      "source": [
        "### Set seed\n",
        "Set a seed value so that when we repeatedly run our code we will get the same result. Using the same seed is important when you want to compare algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeLiwmMNzTqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxNqXnJTzTqY",
        "colab_type": "text"
      },
      "source": [
        "### Import data\n",
        "The Iris dataset contains four features from 150 different Iris flowers. The features in the dataset are described below.\n",
        "\n",
        "* Sepal length (cm)\n",
        "* Sepal width (cm)\n",
        "* Petal length (cm)\n",
        "* Petal width (cm)\n",
        "* Class: Iris setosa, Iris versicolor or Iris virginica\n",
        "\n",
        "Sepals are the part of a flower that protect and support the petals. The petals surround the reproductive parts of the flower.\n",
        "\n",
        "![Iris labeled](http://terpconnect.umd.edu/~petersd/666/html/iris_with_labels.jpg)\n",
        "\n",
        "A snapshot of the dataset is illustrated below (not in order).\n",
        "\n",
        "|Sepal Length|Sepal Width|Petal Length|Petal Width|Class|\n",
        "|---|---|---|---|-----------|\n",
        "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
        "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
        "|7.0|3.2|4.7|1.4|Iris-versicolor|\n",
        "|6.4|3.2|4.5|1.5|Iris-versicolor|\n",
        "|6.3|3.3|6.0|2.5|Iris-virginica|\n",
        "|5.8|2.7|5.1|1.9|Iris-virginica|\n",
        "\n",
        "To load this data into memory, use the `np.loadtxt` function. The data type (`dtype`) is set to `str` because our input data is a mix of numbers and strings. This will be dealt with when we split the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wYz6SEDzTqY",
        "colab_type": "code",
        "outputId": "dd5e945b-7343-4626-eb5c-73aa52052e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "data = np.loadtxt('https://raw.githubusercontent.com/UoA-eResearch/deep-learning-tutorial-2019/master/data/iris.csv', delimiter=\",\", dtype=str)\n",
        "print(data[:20])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['5.1' '3.5' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.9' '3.0' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.7' '3.2' '1.3' '0.2' 'Iris-setosa']\n",
            " ['4.6' '3.1' '1.5' '0.2' 'Iris-setosa']\n",
            " ['5.0' '3.6' '1.4' '0.2' 'Iris-setosa']\n",
            " ['5.4' '3.9' '1.7' '0.4' 'Iris-setosa']\n",
            " ['4.6' '3.4' '1.4' '0.3' 'Iris-setosa']\n",
            " ['5.0' '3.4' '1.5' '0.2' 'Iris-setosa']\n",
            " ['4.4' '2.9' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.9' '3.1' '1.5' '0.1' 'Iris-setosa']\n",
            " ['5.4' '3.7' '1.5' '0.2' 'Iris-setosa']\n",
            " ['4.8' '3.4' '1.6' '0.2' 'Iris-setosa']\n",
            " ['4.8' '3.0' '1.4' '0.1' 'Iris-setosa']\n",
            " ['4.3' '3.0' '1.1' '0.1' 'Iris-setosa']\n",
            " ['5.8' '4.0' '1.2' '0.2' 'Iris-setosa']\n",
            " ['5.7' '4.4' '1.5' '0.4' 'Iris-setosa']\n",
            " ['5.4' '3.9' '1.3' '0.4' 'Iris-setosa']\n",
            " ['5.1' '3.5' '1.4' '0.3' 'Iris-setosa']\n",
            " ['5.7' '3.8' '1.7' '0.3' 'Iris-setosa']\n",
            " ['5.1' '3.8' '1.5' '0.3' 'Iris-setosa']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGLO13AQzTqb",
        "colab_type": "text"
      },
      "source": [
        "Separate the data into input (X) and output (y) variables.\n",
        "\n",
        "Note that we convert the input data into floats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-EcR4awzTqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[:, 0:4].astype(float)\n",
        "y = data[:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zYDMAbzTqd",
        "colab_type": "text"
      },
      "source": [
        "If you look carefully at the target values, you will notice that they are strings, i.e. 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'.\n",
        "\n",
        "Keras needs numbers or matrices to work with, so we will need to reformat the target values.\n",
        "\n",
        "The problem with converting the class values to numbers (e.g. 'Iris-setosa' becomes 0, 'Iris-versicolor' 1 etc) is that it implies that the target values are ordinal. That is, 'Iris-setosa' is somehow less than 'Iris-versicolor'.\n",
        "\n",
        "A better way to represent classes in a multi-class classification problem, is to 'one hot encode' the target values. An example is shown below. A matrix of zeros is generated. Each row corresponds to a sample and each column corresponds to a particular class. A 1 is placed into the column to incidicate the class that it belongs too.\n",
        "\n",
        "|Iris-setosa|Iris-versicolor|Iris-virginica|\n",
        "|---|---|---|\n",
        "|1|0|0|\n",
        "|0|1|0|\n",
        "|0|0|1|\n",
        "\n",
        "One hot encoding is a two step process. First encode the target values (y) into an array of numbers using the `LabelEncoder` from scikit-learn and then one hot encode the numbers with the `np_utils.to_categorical` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmReXRywzTqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_encoded = LabelEncoder().fit(y).transform(y) # Convert the classes into numbers\n",
        "y_one_hot_encoded = np_utils.to_categorical(y_encoded) # One hot encode the numbers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6YS0NRVzTqf",
        "colab_type": "code",
        "outputId": "68f28b41-ef61-49c8-9490-4ec72edfd5ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y_encoded"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQgfvZcfzTqi",
        "colab_type": "code",
        "outputId": "dcc27de1-b095-4075-913b-d4f1b1b347d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_one_hot_encoded[0:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9s47Jx9zTqk",
        "colab_type": "text"
      },
      "source": [
        "Like the previous exercise, use the `train_test_split` function from scikit-learn to split the input and target data into training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qdeRm6LzTql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_encoded, test_size=0.33, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gp1FcnQzTqn",
        "colab_type": "text"
      },
      "source": [
        "### Create the model\n",
        "The code snippet below creates a very basic neural network model, with three layers: an input layer, a hidden layer and an output layer.\n",
        "\n",
        "The first layer is a fully connected `Dense` layer. We use four neurons in the hidden layer and have 4 input neurons for the 4 features.\n",
        "\n",
        "The last layer has 3 neurons, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG9oXx6dzTqn",
        "colab_type": "code",
        "outputId": "67aa39a7-c8dd-4fb9-e606-0049634e5ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=4, activation='relu', kernel_initializer='normal'))\n",
        "model.add(Dense(3, activation='sigmoid', kernel_initializer='normal'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McwgpeyfzTqp",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "We then compile the model. The loss function is set to `categorical_crossentropy` (different from the loss function used in the binary classification exercise) because we are performing multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F86R20yJzTqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr-3q6CEzTqs",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "Now that we have compiled the model, we can train it with the data we prepared earlier. We are using more epochs but a smaller batch size than the previous exercise.\n",
        "\n",
        "To see the model training history in text, just don't include `verbose=0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ohIS-DzTqs",
        "colab_type": "code",
        "outputId": "b583c9bf-5b93-4f16-cde3-0313ae1e6d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6885
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 100 samples, validate on 50 samples\n",
            "Epoch 1/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.0999 - acc: 0.3600 - val_loss: 1.0989 - val_acc: 0.2800\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 0s 322us/step - loss: 1.0974 - acc: 0.5400 - val_loss: 1.0968 - val_acc: 0.6400\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 1.0952 - acc: 0.6800 - val_loss: 1.0942 - val_acc: 0.6400\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 1.0925 - acc: 0.6800 - val_loss: 1.0906 - val_acc: 0.6400\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 1.0886 - acc: 0.6600 - val_loss: 1.0855 - val_acc: 0.6400\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 1.0835 - acc: 0.6800 - val_loss: 1.0795 - val_acc: 0.6400\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 1.0761 - acc: 0.6800 - val_loss: 1.0718 - val_acc: 0.6400\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 1.0667 - acc: 0.6800 - val_loss: 1.0614 - val_acc: 0.6400\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 0s 273us/step - loss: 1.0551 - acc: 0.6800 - val_loss: 1.0493 - val_acc: 0.6400\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 1.0418 - acc: 0.6800 - val_loss: 1.0351 - val_acc: 0.6400\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 1.0254 - acc: 0.6800 - val_loss: 1.0185 - val_acc: 0.6400\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 1.0079 - acc: 0.6800 - val_loss: 1.0012 - val_acc: 0.6400\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.9883 - acc: 0.6800 - val_loss: 0.9816 - val_acc: 0.6400\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.9669 - acc: 0.6800 - val_loss: 0.9608 - val_acc: 0.6400\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 0s 307us/step - loss: 0.9448 - acc: 0.6800 - val_loss: 0.9395 - val_acc: 0.6400\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 0s 321us/step - loss: 0.9207 - acc: 0.6800 - val_loss: 0.9166 - val_acc: 0.6400\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 0s 302us/step - loss: 0.8984 - acc: 0.6800 - val_loss: 0.8957 - val_acc: 0.6400\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.8727 - acc: 0.6800 - val_loss: 0.8715 - val_acc: 0.6400\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.8493 - acc: 0.6800 - val_loss: 0.8494 - val_acc: 0.6400\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.8250 - acc: 0.6800 - val_loss: 0.8281 - val_acc: 0.6400\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.8015 - acc: 0.6800 - val_loss: 0.8073 - val_acc: 0.6400\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.7780 - acc: 0.6800 - val_loss: 0.7859 - val_acc: 0.6400\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.7548 - acc: 0.6800 - val_loss: 0.7649 - val_acc: 0.6400\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.7335 - acc: 0.6800 - val_loss: 0.7460 - val_acc: 0.6400\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 0s 285us/step - loss: 0.7122 - acc: 0.6900 - val_loss: 0.7269 - val_acc: 0.6400\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.6919 - acc: 0.6900 - val_loss: 0.7094 - val_acc: 0.6400\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 0s 298us/step - loss: 0.6729 - acc: 0.6900 - val_loss: 0.6925 - val_acc: 0.6600\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.6551 - acc: 0.6900 - val_loss: 0.6756 - val_acc: 0.6600\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.6381 - acc: 0.7100 - val_loss: 0.6618 - val_acc: 0.6600\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.6197 - acc: 0.7300 - val_loss: 0.6456 - val_acc: 0.6600\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.6052 - acc: 0.7300 - val_loss: 0.6321 - val_acc: 0.6600\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.5891 - acc: 0.7400 - val_loss: 0.6178 - val_acc: 0.7400\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.5747 - acc: 0.7900 - val_loss: 0.6045 - val_acc: 0.8200\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 0s 292us/step - loss: 0.5610 - acc: 0.8500 - val_loss: 0.5921 - val_acc: 0.8600\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.5484 - acc: 0.8900 - val_loss: 0.5796 - val_acc: 0.8600\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.5359 - acc: 0.8900 - val_loss: 0.5689 - val_acc: 0.9200\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 0s 363us/step - loss: 0.5246 - acc: 0.9700 - val_loss: 0.5578 - val_acc: 0.9600\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.5133 - acc: 0.9700 - val_loss: 0.5480 - val_acc: 0.9600\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.5030 - acc: 0.9700 - val_loss: 0.5382 - val_acc: 0.9600\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.4927 - acc: 0.9700 - val_loss: 0.5287 - val_acc: 0.9600\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.4841 - acc: 0.9700 - val_loss: 0.5200 - val_acc: 0.9800\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.4741 - acc: 0.9700 - val_loss: 0.5116 - val_acc: 0.9600\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 0s 286us/step - loss: 0.4667 - acc: 0.9700 - val_loss: 0.5038 - val_acc: 0.9600\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.4589 - acc: 0.9600 - val_loss: 0.4954 - val_acc: 1.0000\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 0s 369us/step - loss: 0.4488 - acc: 0.9700 - val_loss: 0.4876 - val_acc: 0.9800\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.4430 - acc: 0.9700 - val_loss: 0.4805 - val_acc: 0.9600\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.4334 - acc: 0.9700 - val_loss: 0.4728 - val_acc: 0.9800\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.4258 - acc: 0.9700 - val_loss: 0.4659 - val_acc: 0.9800\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.4200 - acc: 0.9600 - val_loss: 0.4589 - val_acc: 0.9800\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.4136 - acc: 0.9700 - val_loss: 0.4529 - val_acc: 0.9600\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.4092 - acc: 0.9700 - val_loss: 0.4463 - val_acc: 1.0000\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 0s 283us/step - loss: 0.4018 - acc: 0.9700 - val_loss: 0.4397 - val_acc: 0.9600\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.3941 - acc: 0.9700 - val_loss: 0.4335 - val_acc: 0.9800\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.3863 - acc: 0.9700 - val_loss: 0.4279 - val_acc: 0.9800\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.3827 - acc: 0.9700 - val_loss: 0.4224 - val_acc: 1.0000\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 0s 232us/step - loss: 0.3748 - acc: 0.9700 - val_loss: 0.4168 - val_acc: 0.9600\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.3700 - acc: 0.9700 - val_loss: 0.4111 - val_acc: 0.9600\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 0s 231us/step - loss: 0.3639 - acc: 0.9700 - val_loss: 0.4061 - val_acc: 0.9800\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.3607 - acc: 0.9600 - val_loss: 0.4007 - val_acc: 1.0000\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.3558 - acc: 0.9700 - val_loss: 0.3963 - val_acc: 0.9600\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.3494 - acc: 0.9700 - val_loss: 0.3908 - val_acc: 0.9800\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.3441 - acc: 0.9700 - val_loss: 0.3858 - val_acc: 0.9800\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.3420 - acc: 0.9700 - val_loss: 0.3815 - val_acc: 0.9800\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.3361 - acc: 0.9700 - val_loss: 0.3774 - val_acc: 0.9800\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 0s 293us/step - loss: 0.3307 - acc: 0.9700 - val_loss: 0.3725 - val_acc: 0.9800\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.3263 - acc: 0.9700 - val_loss: 0.3682 - val_acc: 0.9800\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.3220 - acc: 0.9700 - val_loss: 0.3639 - val_acc: 0.9800\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.3187 - acc: 0.9700 - val_loss: 0.3603 - val_acc: 0.9600\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.3151 - acc: 0.9700 - val_loss: 0.3558 - val_acc: 0.9800\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.3100 - acc: 0.9700 - val_loss: 0.3522 - val_acc: 0.9800\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.3067 - acc: 0.9700 - val_loss: 0.3482 - val_acc: 0.9800\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.3043 - acc: 0.9700 - val_loss: 0.3445 - val_acc: 0.9800\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.2996 - acc: 0.9700 - val_loss: 0.3414 - val_acc: 1.0000\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.2979 - acc: 0.9700 - val_loss: 0.3375 - val_acc: 0.9800\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.2939 - acc: 0.9700 - val_loss: 0.3346 - val_acc: 0.9600\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 0s 306us/step - loss: 0.2909 - acc: 0.9700 - val_loss: 0.3306 - val_acc: 0.9800\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.2863 - acc: 0.9700 - val_loss: 0.3275 - val_acc: 0.9800\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.2844 - acc: 0.9700 - val_loss: 0.3243 - val_acc: 0.9800\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.2817 - acc: 0.9700 - val_loss: 0.3222 - val_acc: 1.0000\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.2772 - acc: 0.9700 - val_loss: 0.3181 - val_acc: 0.9800\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.2749 - acc: 0.9700 - val_loss: 0.3150 - val_acc: 0.9800\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.2709 - acc: 0.9700 - val_loss: 0.3122 - val_acc: 0.9800\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.2696 - acc: 0.9600 - val_loss: 0.3103 - val_acc: 1.0000\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.2656 - acc: 0.9700 - val_loss: 0.3065 - val_acc: 0.9800\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.2644 - acc: 0.9700 - val_loss: 0.3036 - val_acc: 0.9800\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 0s 229us/step - loss: 0.2613 - acc: 0.9700 - val_loss: 0.3007 - val_acc: 0.9800\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.2579 - acc: 0.9700 - val_loss: 0.2982 - val_acc: 0.9800\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.2558 - acc: 0.9600 - val_loss: 0.2959 - val_acc: 1.0000\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.2531 - acc: 0.9700 - val_loss: 0.2925 - val_acc: 0.9800\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.2506 - acc: 0.9700 - val_loss: 0.2905 - val_acc: 0.9800\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.2495 - acc: 0.9700 - val_loss: 0.2878 - val_acc: 0.9800\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.2461 - acc: 0.9700 - val_loss: 0.2851 - val_acc: 0.9800\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.2437 - acc: 0.9600 - val_loss: 0.2832 - val_acc: 1.0000\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.2410 - acc: 0.9600 - val_loss: 0.2803 - val_acc: 0.9800\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.2400 - acc: 0.9700 - val_loss: 0.2779 - val_acc: 0.9800\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.2368 - acc: 0.9600 - val_loss: 0.2762 - val_acc: 0.9800\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.2347 - acc: 0.9600 - val_loss: 0.2736 - val_acc: 0.9800\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.2339 - acc: 0.9700 - val_loss: 0.2709 - val_acc: 0.9800\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.2302 - acc: 0.9700 - val_loss: 0.2692 - val_acc: 0.9800\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.2292 - acc: 0.9600 - val_loss: 0.2670 - val_acc: 0.9800\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.2274 - acc: 0.9700 - val_loss: 0.2646 - val_acc: 0.9800\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.2258 - acc: 0.9600 - val_loss: 0.2626 - val_acc: 0.9800\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.2225 - acc: 0.9600 - val_loss: 0.2622 - val_acc: 1.0000\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.2211 - acc: 0.9600 - val_loss: 0.2586 - val_acc: 0.9800\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.2188 - acc: 0.9700 - val_loss: 0.2565 - val_acc: 0.9800\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.2168 - acc: 0.9700 - val_loss: 0.2550 - val_acc: 0.9800\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.2156 - acc: 0.9600 - val_loss: 0.2536 - val_acc: 1.0000\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.2137 - acc: 0.9700 - val_loss: 0.2508 - val_acc: 0.9800\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.2134 - acc: 0.9600 - val_loss: 0.2489 - val_acc: 0.9800\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.2110 - acc: 0.9700 - val_loss: 0.2474 - val_acc: 0.9800\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.2089 - acc: 0.9700 - val_loss: 0.2462 - val_acc: 1.0000\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.2080 - acc: 0.9700 - val_loss: 0.2442 - val_acc: 0.9800\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.2084 - acc: 0.9600 - val_loss: 0.2419 - val_acc: 0.9800\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.2034 - acc: 0.9700 - val_loss: 0.2409 - val_acc: 0.9800\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 0s 237us/step - loss: 0.2027 - acc: 0.9700 - val_loss: 0.2391 - val_acc: 0.9800\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.2006 - acc: 0.9700 - val_loss: 0.2373 - val_acc: 0.9800\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.2011 - acc: 0.9700 - val_loss: 0.2355 - val_acc: 0.9800\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.2032 - acc: 0.9700 - val_loss: 0.2365 - val_acc: 1.0000\n",
            "Epoch 119/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.1992 - acc: 0.9700 - val_loss: 0.2326 - val_acc: 0.9800\n",
            "Epoch 120/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1967 - acc: 0.9600 - val_loss: 0.2321 - val_acc: 1.0000\n",
            "Epoch 121/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1935 - acc: 0.9700 - val_loss: 0.2293 - val_acc: 0.9800\n",
            "Epoch 122/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.1923 - acc: 0.9700 - val_loss: 0.2278 - val_acc: 0.9800\n",
            "Epoch 123/200\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.1914 - acc: 0.9600 - val_loss: 0.2271 - val_acc: 0.9800\n",
            "Epoch 124/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.1896 - acc: 0.9600 - val_loss: 0.2249 - val_acc: 0.9800\n",
            "Epoch 125/200\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1887 - acc: 0.9700 - val_loss: 0.2239 - val_acc: 0.9800\n",
            "Epoch 126/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1876 - acc: 0.9600 - val_loss: 0.2222 - val_acc: 0.9800\n",
            "Epoch 127/200\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.1856 - acc: 0.9600 - val_loss: 0.2220 - val_acc: 1.0000\n",
            "Epoch 128/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1869 - acc: 0.9800 - val_loss: 0.2209 - val_acc: 1.0000\n",
            "Epoch 129/200\n",
            "100/100 [==============================] - 0s 220us/step - loss: 0.1836 - acc: 0.9700 - val_loss: 0.2180 - val_acc: 0.9800\n",
            "Epoch 130/200\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.1850 - acc: 0.9600 - val_loss: 0.2173 - val_acc: 0.9800\n",
            "Epoch 131/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.1830 - acc: 0.9600 - val_loss: 0.2153 - val_acc: 0.9800\n",
            "Epoch 132/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1813 - acc: 0.9700 - val_loss: 0.2144 - val_acc: 0.9800\n",
            "Epoch 133/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.1821 - acc: 0.9900 - val_loss: 0.2157 - val_acc: 1.0000\n",
            "Epoch 134/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1772 - acc: 0.9700 - val_loss: 0.2127 - val_acc: 1.0000\n",
            "Epoch 135/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.1766 - acc: 0.9600 - val_loss: 0.2107 - val_acc: 0.9800\n",
            "Epoch 136/200\n",
            "100/100 [==============================] - 0s 236us/step - loss: 0.1755 - acc: 0.9600 - val_loss: 0.2094 - val_acc: 0.9800\n",
            "Epoch 137/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.1748 - acc: 0.9700 - val_loss: 0.2081 - val_acc: 0.9800\n",
            "Epoch 138/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.1733 - acc: 0.9600 - val_loss: 0.2077 - val_acc: 0.9800\n",
            "Epoch 139/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1724 - acc: 0.9600 - val_loss: 0.2067 - val_acc: 0.9800\n",
            "Epoch 140/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.1724 - acc: 0.9600 - val_loss: 0.2046 - val_acc: 0.9800\n",
            "Epoch 141/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1696 - acc: 0.9700 - val_loss: 0.2043 - val_acc: 0.9800\n",
            "Epoch 142/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.1694 - acc: 0.9600 - val_loss: 0.2036 - val_acc: 1.0000\n",
            "Epoch 143/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1688 - acc: 0.9700 - val_loss: 0.2031 - val_acc: 1.0000\n",
            "Epoch 144/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.1692 - acc: 0.9600 - val_loss: 0.2002 - val_acc: 0.9800\n",
            "Epoch 145/200\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.1658 - acc: 0.9700 - val_loss: 0.1996 - val_acc: 0.9800\n",
            "Epoch 146/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.1657 - acc: 0.9700 - val_loss: 0.1995 - val_acc: 1.0000\n",
            "Epoch 147/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.1655 - acc: 0.9600 - val_loss: 0.1981 - val_acc: 0.9800\n",
            "Epoch 148/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.1639 - acc: 0.9600 - val_loss: 0.1963 - val_acc: 0.9800\n",
            "Epoch 149/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1629 - acc: 0.9600 - val_loss: 0.1961 - val_acc: 0.9800\n",
            "Epoch 150/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1630 - acc: 0.9700 - val_loss: 0.1958 - val_acc: 1.0000\n",
            "Epoch 151/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.1609 - acc: 0.9700 - val_loss: 0.1931 - val_acc: 0.9800\n",
            "Epoch 152/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.1630 - acc: 0.9700 - val_loss: 0.1940 - val_acc: 1.0000\n",
            "Epoch 153/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1592 - acc: 0.9800 - val_loss: 0.1912 - val_acc: 0.9800\n",
            "Epoch 154/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1587 - acc: 0.9600 - val_loss: 0.1910 - val_acc: 0.9800\n",
            "Epoch 155/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1573 - acc: 0.9600 - val_loss: 0.1901 - val_acc: 0.9800\n",
            "Epoch 156/200\n",
            "100/100 [==============================] - 0s 303us/step - loss: 0.1563 - acc: 0.9700 - val_loss: 0.1893 - val_acc: 0.9800\n",
            "Epoch 157/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1577 - acc: 0.9600 - val_loss: 0.1877 - val_acc: 0.9800\n",
            "Epoch 158/200\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1555 - acc: 0.9600 - val_loss: 0.1886 - val_acc: 1.0000\n",
            "Epoch 159/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.1546 - acc: 0.9700 - val_loss: 0.1870 - val_acc: 1.0000\n",
            "Epoch 160/200\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.1544 - acc: 0.9700 - val_loss: 0.1848 - val_acc: 0.9800\n",
            "Epoch 161/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1528 - acc: 0.9700 - val_loss: 0.1849 - val_acc: 0.9800\n",
            "Epoch 162/200\n",
            "100/100 [==============================] - 0s 233us/step - loss: 0.1525 - acc: 0.9600 - val_loss: 0.1839 - val_acc: 0.9800\n",
            "Epoch 163/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.1517 - acc: 0.9600 - val_loss: 0.1828 - val_acc: 0.9800\n",
            "Epoch 164/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1504 - acc: 0.9600 - val_loss: 0.1820 - val_acc: 0.9800\n",
            "Epoch 165/200\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.1493 - acc: 0.9600 - val_loss: 0.1808 - val_acc: 0.9800\n",
            "Epoch 166/200\n",
            "100/100 [==============================] - 0s 240us/step - loss: 0.1494 - acc: 0.9700 - val_loss: 0.1814 - val_acc: 1.0000\n",
            "Epoch 167/200\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.1482 - acc: 0.9600 - val_loss: 0.1789 - val_acc: 0.9800\n",
            "Epoch 168/200\n",
            "100/100 [==============================] - 0s 295us/step - loss: 0.1483 - acc: 0.9600 - val_loss: 0.1792 - val_acc: 0.9800\n",
            "Epoch 169/200\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.1465 - acc: 0.9700 - val_loss: 0.1776 - val_acc: 0.9800\n",
            "Epoch 170/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1462 - acc: 0.9600 - val_loss: 0.1769 - val_acc: 0.9800\n",
            "Epoch 171/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.1454 - acc: 0.9600 - val_loss: 0.1758 - val_acc: 0.9800\n",
            "Epoch 172/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.1463 - acc: 0.9600 - val_loss: 0.1762 - val_acc: 0.9800\n",
            "Epoch 173/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.1436 - acc: 0.9600 - val_loss: 0.1747 - val_acc: 0.9800\n",
            "Epoch 174/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.1434 - acc: 0.9600 - val_loss: 0.1736 - val_acc: 0.9800\n",
            "Epoch 175/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.1423 - acc: 0.9600 - val_loss: 0.1731 - val_acc: 0.9800\n",
            "Epoch 176/200\n",
            "100/100 [==============================] - 0s 226us/step - loss: 0.1422 - acc: 0.9600 - val_loss: 0.1720 - val_acc: 0.9800\n",
            "Epoch 177/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.1422 - acc: 0.9700 - val_loss: 0.1724 - val_acc: 0.9800\n",
            "Epoch 178/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.1424 - acc: 0.9700 - val_loss: 0.1734 - val_acc: 1.0000\n",
            "Epoch 179/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.1403 - acc: 0.9600 - val_loss: 0.1699 - val_acc: 0.9800\n",
            "Epoch 180/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1402 - acc: 0.9600 - val_loss: 0.1693 - val_acc: 0.9800\n",
            "Epoch 181/200\n",
            "100/100 [==============================] - 0s 292us/step - loss: 0.1394 - acc: 0.9600 - val_loss: 0.1687 - val_acc: 0.9800\n",
            "Epoch 182/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1383 - acc: 0.9700 - val_loss: 0.1687 - val_acc: 0.9800\n",
            "Epoch 183/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1377 - acc: 0.9700 - val_loss: 0.1684 - val_acc: 0.9800\n",
            "Epoch 184/200\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1371 - acc: 0.9600 - val_loss: 0.1673 - val_acc: 0.9800\n",
            "Epoch 185/200\n",
            "100/100 [==============================] - 0s 228us/step - loss: 0.1361 - acc: 0.9700 - val_loss: 0.1667 - val_acc: 0.9800\n",
            "Epoch 186/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1357 - acc: 0.9600 - val_loss: 0.1658 - val_acc: 0.9800\n",
            "Epoch 187/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1354 - acc: 0.9700 - val_loss: 0.1647 - val_acc: 0.9800\n",
            "Epoch 188/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1345 - acc: 0.9600 - val_loss: 0.1644 - val_acc: 0.9800\n",
            "Epoch 189/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1375 - acc: 0.9700 - val_loss: 0.1644 - val_acc: 0.9800\n",
            "Epoch 190/200\n",
            "100/100 [==============================] - 0s 222us/step - loss: 0.1328 - acc: 0.9700 - val_loss: 0.1631 - val_acc: 0.9800\n",
            "Epoch 191/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1328 - acc: 0.9600 - val_loss: 0.1621 - val_acc: 0.9800\n",
            "Epoch 192/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1324 - acc: 0.9600 - val_loss: 0.1619 - val_acc: 0.9800\n",
            "Epoch 193/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1326 - acc: 0.9600 - val_loss: 0.1613 - val_acc: 0.9800\n",
            "Epoch 194/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.1317 - acc: 0.9700 - val_loss: 0.1608 - val_acc: 0.9800\n",
            "Epoch 195/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.1304 - acc: 0.9600 - val_loss: 0.1598 - val_acc: 0.9800\n",
            "Epoch 196/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1306 - acc: 0.9600 - val_loss: 0.1593 - val_acc: 0.9800\n",
            "Epoch 197/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.1300 - acc: 0.9700 - val_loss: 0.1597 - val_acc: 0.9800\n",
            "Epoch 198/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1291 - acc: 0.9700 - val_loss: 0.1579 - val_acc: 0.9800\n",
            "Epoch 199/200\n",
            "100/100 [==============================] - 0s 230us/step - loss: 0.1309 - acc: 0.9600 - val_loss: 0.1590 - val_acc: 1.0000\n",
            "Epoch 200/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.1288 - acc: 0.9700 - val_loss: 0.1569 - val_acc: 0.9800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwYPK696zTqu",
        "colab_type": "code",
        "outputId": "7563c199-1d2c-4d87-f6f9-bcb1a3d86ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plot_acc_loss(history)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJcCAYAAAA7Pup5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwHuS2MdV5k/LAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw2wWtw5zTqy",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model\n",
        "Now that we have trained our model, we can evaluate the performance on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQtZLcOdzTq0",
        "colab_type": "code",
        "outputId": "45fd452a-a14a-46b0-cb06-e4a4775b4b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "scores = model.evaluate(X, y_one_hot_encoded)\n",
        "print(\"\\n\\n{0}: {1:.2f}%\".format(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 0s 58us/step\n",
            "\n",
            "\n",
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEnF0buSzTq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCgD2TCKzTq8",
        "colab_type": "code",
        "outputId": "046eaab6-c0c9-446d-a51e-ce026b24cdf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "matrix = metrics.confusion_matrix(y_encoded, y_pred) # (y_true,y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[50  0  0]\n",
            " [ 0 46  4]\n",
            " [ 0  1 49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhOFX6LUzTrD",
        "colab_type": "code",
        "outputId": "fd26a3f7-1f72-4ffd-dc71-bae091320166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(50+46+49)/(50+46+49+1+4)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vC9cL_a0FJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}