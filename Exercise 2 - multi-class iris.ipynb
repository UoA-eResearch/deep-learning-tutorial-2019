{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 2 - multi-class iris.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UoA-eResearch/deep-learning-tutorial-2019/blob/master/Exercise%202%20-%20multi-class%20iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPQTvjnTzTqM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2: The Iris Dataset\n",
        "In this exercise we will create a neural network to classify 3 different types of Iris (Setosa, Versicolor and Virginica) based on their sepal length, sepal width, petal length and petal width.\n",
        "\n",
        "![Irises](http://dataaspirant.com/wp-content/uploads/2017/01/irises.png)\n",
        "\n",
        "This is a multi class classification problem. It is similar to the Pima Indian's binary classification exercise, but with three classes to predict instead of two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9VrMNin1Yi",
        "colab_type": "text"
      },
      "source": [
        "### Q: How many steps are there in creating a neural network model? Please list those steps\n",
        "\n",
        "*answer...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B9pUqCzTqO",
        "colab_type": "text"
      },
      "source": [
        "### Import dependencies\n",
        "Start by importing the dependencies we will need for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB8CJHppzTqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxNqXnJTzTqY",
        "colab_type": "text"
      },
      "source": [
        "### Import data\n",
        "The Iris dataset contains four features from 150 different Iris flowers. The features in the dataset are described below.\n",
        "\n",
        "* Sepal length (cm)\n",
        "* Sepal width (cm)\n",
        "* Petal length (cm)\n",
        "* Petal width (cm)\n",
        "* Class: Iris setosa, Iris versicolor or Iris virginica\n",
        "\n",
        "Sepals are the part of a flower that protect and support the petals. The petals surround the reproductive parts of the flower.\n",
        "\n",
        "![Iris labeled](http://terpconnect.umd.edu/~petersd/666/html/iris_with_labels.jpg)\n",
        "\n",
        "A snapshot of the dataset is illustrated below (not in order).\n",
        "\n",
        "|Sepal Length|Sepal Width|Petal Length|Petal Width|Class|\n",
        "|---|---|---|---|-----------|\n",
        "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
        "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
        "|7.0|3.2|4.7|1.4|Iris-versicolor|\n",
        "|6.4|3.2|4.5|1.5|Iris-versicolor|\n",
        "|6.3|3.3|6.0|2.5|Iris-virginica|\n",
        "|5.8|2.7|5.1|1.9|Iris-virginica|\n",
        "\n",
        "To load this data into memory, use the `np.loadtxt` function. The data type (`dtype`) is set to `str` because our input data is a mix of numbers and strings. This will be dealt with when we split the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wYz6SEDzTqY",
        "colab_type": "code",
        "outputId": "3ec4cf0c-9c93-495b-fbf8-aff2f2879f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data = np.loadtxt('https://raw.githubusercontent.com/UoA-eResearch/deep-learning-tutorial-2019/master/data/iris.csv', delimiter=\",\", dtype=str)\n",
        "print(data[:6]) #Show the first 6 rows"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['5.1' '3.5' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.9' '3.0' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.7' '3.2' '1.3' '0.2' 'Iris-setosa']\n",
            " ['4.6' '3.1' '1.5' '0.2' 'Iris-setosa']\n",
            " ['5.0' '3.6' '1.4' '0.2' 'Iris-setosa']\n",
            " ['5.4' '3.9' '1.7' '0.4' 'Iris-setosa']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGLO13AQzTqb",
        "colab_type": "text"
      },
      "source": [
        "Separate the data into input (X) and output (y) variables.\n",
        "\n",
        "Note that we convert the input data into floats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-EcR4awzTqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[:, 0:4].astype(float)\n",
        "y = data[:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zYDMAbzTqd",
        "colab_type": "text"
      },
      "source": [
        "If you look carefully at the target values, you will notice that they are strings, i.e. 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'.\n",
        "\n",
        "**Keras needs numbers or matrices to work with, so we will need to reformat the target values.**\n",
        "\n",
        "The problem with converting the class values to numbers (e.g. 'Iris-setosa' becomes 0, 'Iris-versicolor' 1 etc) is that it implies that the target values are ordinal. That is, 'Iris-setosa' is somehow less than 'Iris-versicolor', which is not the case for this dataset.\n",
        "\n",
        "A better way to represent classes in a multi-class classification problem, is to 'one hot encode' the target values. An example is shown below. A matrix of zeros is generated. Each row corresponds to a sample and each column corresponds to a particular class. A 1 is placed into the column to incidicate the class that it belongs too.\n",
        "\n",
        "|Iris-setosa|Iris-versicolor|Iris-virginica|\n",
        "|---|---|---|\n",
        "|1|0|0|\n",
        "|0|1|0|\n",
        "|0|0|1|\n",
        "\n",
        "One hot encoding is a two step process. First encode the target values (y) into an array of numbers using the `LabelEncoder` from scikit-learn and then one hot encode the numbers with the `np_utils.to_categorical` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmReXRywzTqe",
        "colab_type": "code",
        "outputId": "66683262-6b7d-4108-ccf7-356f4130ee0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_encoded = LabelEncoder().fit(y).transform(y) # Convert the classes into numbers\n",
        "y_encoded[45:55]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQgfvZcfzTqi",
        "colab_type": "code",
        "outputId": "b77a025e-74b2-4dd4-ef92-4203fae552d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_one_hot_encoded = np_utils.to_categorical(y_encoded) # One hot encode the numbers\n",
        "y_one_hot_encoded[45:55]"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMbd6-LV9Rm_",
        "colab_type": "text"
      },
      "source": [
        "### Set seed\n",
        "Set a seed value so that when we repeatedly run our code we will get the same result. Using the same seed is important when you want to compare algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvjmpbYM9UN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9s47Jx9zTqk",
        "colab_type": "text"
      },
      "source": [
        "Like the previous exercise, use the `train_test_split` function from scikit-learn to split the input and target data into training, validation and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qdeRm6LzTql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_encoded, test_size=0.2, random_state=seed)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gp1FcnQzTqn",
        "colab_type": "text"
      },
      "source": [
        "### Create the model\n",
        "The code snippet below creates a very basic neural network model, with three layers: an input layer, a hidden layer and an output layer.\n",
        "\n",
        "The first layer is a fully connected `Dense` layer. We use four neurons in the hidden layer and have 4 input neurons for the 4 features.\n",
        "\n",
        "The last layer has 3 neurons, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG9oXx6dzTqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=4, activation='relu', kernel_initializer='normal'))\n",
        "model.add(Dense(3, activation='sigmoid', kernel_initializer='normal'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McwgpeyfzTqp",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "We then compile the model. The loss function is set to `categorical_crossentropy` (different from the loss function used in the binary classification exercise) because we are performing multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F86R20yJzTqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr-3q6CEzTqs",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "Now that we have compiled the model, we can train it with the data we prepared earlier. We are using more epochs but a smaller batch size than the previous exercise.\n",
        "\n",
        "To see the model training history in text, just don't include `verbose=0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ohIS-DzTqs",
        "colab_type": "code",
        "outputId": "0252675e-a079-4ea4-963b-27556f9d04bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=5)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 96 samples, validate on 24 samples\n",
            "Epoch 1/200\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 1.0998 - acc: 0.3438 - val_loss: 1.0979 - val_acc: 0.4167\n",
            "Epoch 2/200\n",
            "96/96 [==============================] - 0s 309us/step - loss: 1.0972 - acc: 0.5833 - val_loss: 1.0968 - val_acc: 0.6667\n",
            "Epoch 3/200\n",
            "96/96 [==============================] - 0s 341us/step - loss: 1.0953 - acc: 0.6458 - val_loss: 1.0951 - val_acc: 0.6250\n",
            "Epoch 4/200\n",
            "96/96 [==============================] - 0s 311us/step - loss: 1.0927 - acc: 0.3854 - val_loss: 1.0932 - val_acc: 0.2500\n",
            "Epoch 5/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 1.0888 - acc: 0.3438 - val_loss: 1.0900 - val_acc: 0.2500\n",
            "Epoch 6/200\n",
            "96/96 [==============================] - 0s 365us/step - loss: 1.0836 - acc: 0.3438 - val_loss: 1.0856 - val_acc: 0.2500\n",
            "Epoch 7/200\n",
            "96/96 [==============================] - 0s 415us/step - loss: 1.0771 - acc: 0.3854 - val_loss: 1.0793 - val_acc: 0.4167\n",
            "Epoch 8/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 1.0690 - acc: 0.5625 - val_loss: 1.0708 - val_acc: 0.6250\n",
            "Epoch 9/200\n",
            "96/96 [==============================] - 0s 323us/step - loss: 1.0587 - acc: 0.6458 - val_loss: 1.0613 - val_acc: 0.6667\n",
            "Epoch 10/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 1.0471 - acc: 0.6563 - val_loss: 1.0500 - val_acc: 0.6667\n",
            "Epoch 11/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 1.0337 - acc: 0.6875 - val_loss: 1.0358 - val_acc: 0.6667\n",
            "Epoch 12/200\n",
            "96/96 [==============================] - 0s 315us/step - loss: 1.0183 - acc: 0.6875 - val_loss: 1.0205 - val_acc: 0.6667\n",
            "Epoch 13/200\n",
            "96/96 [==============================] - 0s 333us/step - loss: 1.0002 - acc: 0.6875 - val_loss: 1.0005 - val_acc: 0.6667\n",
            "Epoch 14/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.9807 - acc: 0.6875 - val_loss: 0.9817 - val_acc: 0.6667\n",
            "Epoch 15/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.9590 - acc: 0.6875 - val_loss: 0.9599 - val_acc: 0.6667\n",
            "Epoch 16/200\n",
            "96/96 [==============================] - 0s 381us/step - loss: 0.9380 - acc: 0.6875 - val_loss: 0.9369 - val_acc: 0.6667\n",
            "Epoch 17/200\n",
            "96/96 [==============================] - 0s 309us/step - loss: 0.9173 - acc: 0.6875 - val_loss: 0.9173 - val_acc: 0.6667\n",
            "Epoch 18/200\n",
            "96/96 [==============================] - 0s 312us/step - loss: 0.8927 - acc: 0.6875 - val_loss: 0.8919 - val_acc: 0.6667\n",
            "Epoch 19/200\n",
            "96/96 [==============================] - 0s 341us/step - loss: 0.8703 - acc: 0.6875 - val_loss: 0.8680 - val_acc: 0.6667\n",
            "Epoch 20/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.8476 - acc: 0.6875 - val_loss: 0.8431 - val_acc: 0.6667\n",
            "Epoch 21/200\n",
            "96/96 [==============================] - 0s 329us/step - loss: 0.8253 - acc: 0.6875 - val_loss: 0.8195 - val_acc: 0.6667\n",
            "Epoch 22/200\n",
            "96/96 [==============================] - 0s 362us/step - loss: 0.8028 - acc: 0.6875 - val_loss: 0.7985 - val_acc: 0.6667\n",
            "Epoch 23/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.7816 - acc: 0.6875 - val_loss: 0.7745 - val_acc: 0.6667\n",
            "Epoch 24/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.7593 - acc: 0.6875 - val_loss: 0.7507 - val_acc: 0.6667\n",
            "Epoch 25/200\n",
            "96/96 [==============================] - 0s 345us/step - loss: 0.7383 - acc: 0.6875 - val_loss: 0.7297 - val_acc: 0.6667\n",
            "Epoch 26/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.7186 - acc: 0.6875 - val_loss: 0.7065 - val_acc: 0.6667\n",
            "Epoch 27/200\n",
            "96/96 [==============================] - 0s 315us/step - loss: 0.6993 - acc: 0.6875 - val_loss: 0.6898 - val_acc: 0.6667\n",
            "Epoch 28/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.6798 - acc: 0.6875 - val_loss: 0.6670 - val_acc: 0.6667\n",
            "Epoch 29/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.6623 - acc: 0.6875 - val_loss: 0.6502 - val_acc: 0.6667\n",
            "Epoch 30/200\n",
            "96/96 [==============================] - 0s 336us/step - loss: 0.6441 - acc: 0.6875 - val_loss: 0.6306 - val_acc: 0.6667\n",
            "Epoch 31/200\n",
            "96/96 [==============================] - 0s 339us/step - loss: 0.6286 - acc: 0.6875 - val_loss: 0.6148 - val_acc: 0.7083\n",
            "Epoch 32/200\n",
            "96/96 [==============================] - 0s 338us/step - loss: 0.6133 - acc: 0.6875 - val_loss: 0.5959 - val_acc: 0.7083\n",
            "Epoch 33/200\n",
            "96/96 [==============================] - 0s 334us/step - loss: 0.5977 - acc: 0.7083 - val_loss: 0.5808 - val_acc: 0.7083\n",
            "Epoch 34/200\n",
            "96/96 [==============================] - 0s 321us/step - loss: 0.5833 - acc: 0.7083 - val_loss: 0.5659 - val_acc: 0.7083\n",
            "Epoch 35/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.5692 - acc: 0.7292 - val_loss: 0.5491 - val_acc: 0.7083\n",
            "Epoch 36/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.5558 - acc: 0.8125 - val_loss: 0.5340 - val_acc: 0.7917\n",
            "Epoch 37/200\n",
            "96/96 [==============================] - 0s 444us/step - loss: 0.5433 - acc: 0.7708 - val_loss: 0.5245 - val_acc: 0.7083\n",
            "Epoch 38/200\n",
            "96/96 [==============================] - 0s 343us/step - loss: 0.5311 - acc: 0.8333 - val_loss: 0.5094 - val_acc: 0.8333\n",
            "Epoch 39/200\n",
            "96/96 [==============================] - 0s 302us/step - loss: 0.5195 - acc: 0.8542 - val_loss: 0.4987 - val_acc: 0.8333\n",
            "Epoch 40/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.5084 - acc: 0.8854 - val_loss: 0.4847 - val_acc: 0.9167\n",
            "Epoch 41/200\n",
            "96/96 [==============================] - 0s 346us/step - loss: 0.4971 - acc: 0.9167 - val_loss: 0.4749 - val_acc: 0.9167\n",
            "Epoch 42/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.4889 - acc: 0.8750 - val_loss: 0.4668 - val_acc: 0.8333\n",
            "Epoch 43/200\n",
            "96/96 [==============================] - 0s 331us/step - loss: 0.4779 - acc: 0.8750 - val_loss: 0.4577 - val_acc: 0.8333\n",
            "Epoch 44/200\n",
            "96/96 [==============================] - 0s 348us/step - loss: 0.4678 - acc: 0.8958 - val_loss: 0.4466 - val_acc: 0.9167\n",
            "Epoch 45/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.4588 - acc: 0.9271 - val_loss: 0.4372 - val_acc: 0.9167\n",
            "Epoch 46/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.4499 - acc: 0.9688 - val_loss: 0.4285 - val_acc: 0.9167\n",
            "Epoch 47/200\n",
            "96/96 [==============================] - 0s 312us/step - loss: 0.4414 - acc: 0.9375 - val_loss: 0.4214 - val_acc: 0.9167\n",
            "Epoch 48/200\n",
            "96/96 [==============================] - 0s 317us/step - loss: 0.4337 - acc: 0.9167 - val_loss: 0.4136 - val_acc: 0.9167\n",
            "Epoch 49/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.4268 - acc: 0.8958 - val_loss: 0.4085 - val_acc: 0.9167\n",
            "Epoch 50/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.4174 - acc: 0.9271 - val_loss: 0.3979 - val_acc: 0.9583\n",
            "Epoch 51/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.4101 - acc: 0.9792 - val_loss: 0.3901 - val_acc: 0.9583\n",
            "Epoch 52/200\n",
            "96/96 [==============================] - 0s 349us/step - loss: 0.4035 - acc: 0.9792 - val_loss: 0.3845 - val_acc: 0.9583\n",
            "Epoch 53/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.3990 - acc: 0.9792 - val_loss: 0.3752 - val_acc: 0.9583\n",
            "Epoch 54/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.3894 - acc: 0.9792 - val_loss: 0.3735 - val_acc: 0.9583\n",
            "Epoch 55/200\n",
            "96/96 [==============================] - 0s 306us/step - loss: 0.3841 - acc: 0.9583 - val_loss: 0.3689 - val_acc: 0.9583\n",
            "Epoch 56/200\n",
            "96/96 [==============================] - 0s 272us/step - loss: 0.3795 - acc: 0.9792 - val_loss: 0.3584 - val_acc: 0.9583\n",
            "Epoch 57/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.3715 - acc: 0.9792 - val_loss: 0.3577 - val_acc: 0.9583\n",
            "Epoch 58/200\n",
            "96/96 [==============================] - 0s 260us/step - loss: 0.3661 - acc: 0.9792 - val_loss: 0.3507 - val_acc: 0.9583\n",
            "Epoch 59/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.3609 - acc: 0.9792 - val_loss: 0.3442 - val_acc: 0.9583\n",
            "Epoch 60/200\n",
            "96/96 [==============================] - 0s 316us/step - loss: 0.3558 - acc: 0.9792 - val_loss: 0.3436 - val_acc: 0.9583\n",
            "Epoch 61/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.3516 - acc: 0.9792 - val_loss: 0.3346 - val_acc: 0.9583\n",
            "Epoch 62/200\n",
            "96/96 [==============================] - 0s 342us/step - loss: 0.3473 - acc: 0.9792 - val_loss: 0.3307 - val_acc: 0.9583\n",
            "Epoch 63/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.3413 - acc: 0.9792 - val_loss: 0.3262 - val_acc: 0.9583\n",
            "Epoch 64/200\n",
            "96/96 [==============================] - 0s 318us/step - loss: 0.3386 - acc: 0.9792 - val_loss: 0.3221 - val_acc: 0.9583\n",
            "Epoch 65/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.3322 - acc: 0.9792 - val_loss: 0.3197 - val_acc: 0.9583\n",
            "Epoch 66/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.3286 - acc: 0.9792 - val_loss: 0.3188 - val_acc: 0.9583\n",
            "Epoch 67/200\n",
            "96/96 [==============================] - 0s 306us/step - loss: 0.3237 - acc: 0.9792 - val_loss: 0.3097 - val_acc: 0.9583\n",
            "Epoch 68/200\n",
            "96/96 [==============================] - 0s 309us/step - loss: 0.3220 - acc: 0.9792 - val_loss: 0.3091 - val_acc: 0.9583\n",
            "Epoch 69/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.3163 - acc: 0.9792 - val_loss: 0.3045 - val_acc: 0.9583\n",
            "Epoch 70/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.3150 - acc: 0.9792 - val_loss: 0.3039 - val_acc: 0.9583\n",
            "Epoch 71/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.3086 - acc: 0.9792 - val_loss: 0.2959 - val_acc: 0.9583\n",
            "Epoch 72/200\n",
            "96/96 [==============================] - 0s 364us/step - loss: 0.3067 - acc: 0.9792 - val_loss: 0.2921 - val_acc: 0.9583\n",
            "Epoch 73/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.3026 - acc: 0.9792 - val_loss: 0.2910 - val_acc: 0.9583\n",
            "Epoch 74/200\n",
            "96/96 [==============================] - 0s 302us/step - loss: 0.3035 - acc: 0.9792 - val_loss: 0.2944 - val_acc: 0.9583\n",
            "Epoch 75/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.2962 - acc: 0.9792 - val_loss: 0.2860 - val_acc: 0.9583\n",
            "Epoch 76/200\n",
            "96/96 [==============================] - 0s 302us/step - loss: 0.2921 - acc: 0.9792 - val_loss: 0.2855 - val_acc: 0.9583\n",
            "Epoch 77/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.2895 - acc: 0.9792 - val_loss: 0.2843 - val_acc: 0.9583\n",
            "Epoch 78/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.2878 - acc: 0.9792 - val_loss: 0.2818 - val_acc: 0.9583\n",
            "Epoch 79/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.2833 - acc: 0.9792 - val_loss: 0.2744 - val_acc: 0.9583\n",
            "Epoch 80/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.2813 - acc: 0.9792 - val_loss: 0.2716 - val_acc: 0.9583\n",
            "Epoch 81/200\n",
            "96/96 [==============================] - 0s 313us/step - loss: 0.2780 - acc: 0.9792 - val_loss: 0.2698 - val_acc: 0.9583\n",
            "Epoch 82/200\n",
            "96/96 [==============================] - 0s 308us/step - loss: 0.2766 - acc: 0.9792 - val_loss: 0.2710 - val_acc: 0.9583\n",
            "Epoch 83/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.2732 - acc: 0.9792 - val_loss: 0.2668 - val_acc: 0.9583\n",
            "Epoch 84/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.2718 - acc: 0.9792 - val_loss: 0.2667 - val_acc: 0.9583\n",
            "Epoch 85/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.2677 - acc: 0.9792 - val_loss: 0.2592 - val_acc: 0.9583\n",
            "Epoch 86/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.2658 - acc: 0.9792 - val_loss: 0.2545 - val_acc: 0.9583\n",
            "Epoch 87/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.2656 - acc: 0.9792 - val_loss: 0.2561 - val_acc: 0.9583\n",
            "Epoch 88/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.2638 - acc: 0.9792 - val_loss: 0.2508 - val_acc: 0.9583\n",
            "Epoch 89/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.2587 - acc: 0.9792 - val_loss: 0.2529 - val_acc: 0.9583\n",
            "Epoch 90/200\n",
            "96/96 [==============================] - 0s 314us/step - loss: 0.2558 - acc: 0.9792 - val_loss: 0.2479 - val_acc: 0.9583\n",
            "Epoch 91/200\n",
            "96/96 [==============================] - 0s 318us/step - loss: 0.2536 - acc: 0.9792 - val_loss: 0.2495 - val_acc: 0.9583\n",
            "Epoch 92/200\n",
            "96/96 [==============================] - 0s 287us/step - loss: 0.2514 - acc: 0.9792 - val_loss: 0.2486 - val_acc: 0.9583\n",
            "Epoch 93/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.2509 - acc: 0.9792 - val_loss: 0.2478 - val_acc: 0.9583\n",
            "Epoch 94/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.2469 - acc: 0.9792 - val_loss: 0.2396 - val_acc: 0.9583\n",
            "Epoch 95/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.2442 - acc: 0.9792 - val_loss: 0.2382 - val_acc: 0.9583\n",
            "Epoch 96/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.2443 - acc: 0.9792 - val_loss: 0.2394 - val_acc: 0.9583\n",
            "Epoch 97/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.2407 - acc: 0.9792 - val_loss: 0.2353 - val_acc: 0.9583\n",
            "Epoch 98/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.2386 - acc: 0.9792 - val_loss: 0.2306 - val_acc: 0.9583\n",
            "Epoch 99/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.2360 - acc: 0.9792 - val_loss: 0.2305 - val_acc: 0.9583\n",
            "Epoch 100/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.2356 - acc: 0.9792 - val_loss: 0.2322 - val_acc: 0.9583\n",
            "Epoch 101/200\n",
            "96/96 [==============================] - 0s 332us/step - loss: 0.2332 - acc: 0.9792 - val_loss: 0.2282 - val_acc: 0.9583\n",
            "Epoch 102/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.2301 - acc: 0.9792 - val_loss: 0.2258 - val_acc: 0.9583\n",
            "Epoch 103/200\n",
            "96/96 [==============================] - 0s 327us/step - loss: 0.2329 - acc: 0.9688 - val_loss: 0.2200 - val_acc: 0.9583\n",
            "Epoch 104/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.2279 - acc: 0.9792 - val_loss: 0.2235 - val_acc: 0.9583\n",
            "Epoch 105/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.2253 - acc: 0.9792 - val_loss: 0.2196 - val_acc: 0.9583\n",
            "Epoch 106/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.2227 - acc: 0.9792 - val_loss: 0.2191 - val_acc: 0.9583\n",
            "Epoch 107/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.2230 - acc: 0.9792 - val_loss: 0.2206 - val_acc: 0.9583\n",
            "Epoch 108/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.2211 - acc: 0.9792 - val_loss: 0.2179 - val_acc: 0.9583\n",
            "Epoch 109/200\n",
            "96/96 [==============================] - 0s 323us/step - loss: 0.2191 - acc: 0.9792 - val_loss: 0.2143 - val_acc: 0.9583\n",
            "Epoch 110/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.2166 - acc: 0.9792 - val_loss: 0.2123 - val_acc: 0.9583\n",
            "Epoch 111/200\n",
            "96/96 [==============================] - 0s 330us/step - loss: 0.2149 - acc: 0.9792 - val_loss: 0.2088 - val_acc: 0.9583\n",
            "Epoch 112/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.2151 - acc: 0.9792 - val_loss: 0.2105 - val_acc: 0.9583\n",
            "Epoch 113/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.2124 - acc: 0.9792 - val_loss: 0.2076 - val_acc: 0.9583\n",
            "Epoch 114/200\n",
            "96/96 [==============================] - 0s 317us/step - loss: 0.2101 - acc: 0.9792 - val_loss: 0.2062 - val_acc: 0.9583\n",
            "Epoch 115/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.2095 - acc: 0.9792 - val_loss: 0.2070 - val_acc: 0.9583\n",
            "Epoch 116/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.2057 - acc: 0.9792 - val_loss: 0.1996 - val_acc: 0.9583\n",
            "Epoch 117/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.2056 - acc: 0.9792 - val_loss: 0.1999 - val_acc: 0.9583\n",
            "Epoch 118/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.2038 - acc: 0.9792 - val_loss: 0.1981 - val_acc: 0.9583\n",
            "Epoch 119/200\n",
            "96/96 [==============================] - 0s 302us/step - loss: 0.2023 - acc: 0.9792 - val_loss: 0.2016 - val_acc: 0.9583\n",
            "Epoch 120/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.2019 - acc: 0.9792 - val_loss: 0.1976 - val_acc: 0.9583\n",
            "Epoch 121/200\n",
            "96/96 [==============================] - 0s 339us/step - loss: 0.1991 - acc: 0.9792 - val_loss: 0.1994 - val_acc: 0.9583\n",
            "Epoch 122/200\n",
            "96/96 [==============================] - 0s 311us/step - loss: 0.1987 - acc: 0.9792 - val_loss: 0.1962 - val_acc: 0.9583\n",
            "Epoch 123/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.1966 - acc: 0.9792 - val_loss: 0.1948 - val_acc: 0.9583\n",
            "Epoch 124/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.1971 - acc: 0.9792 - val_loss: 0.1998 - val_acc: 0.9583\n",
            "Epoch 125/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.1950 - acc: 0.9792 - val_loss: 0.1945 - val_acc: 0.9583\n",
            "Epoch 126/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.1952 - acc: 0.9792 - val_loss: 0.1844 - val_acc: 0.9583\n",
            "Epoch 127/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.1939 - acc: 0.9688 - val_loss: 0.1896 - val_acc: 0.9583\n",
            "Epoch 128/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.1903 - acc: 0.9792 - val_loss: 0.1833 - val_acc: 0.9583\n",
            "Epoch 129/200\n",
            "96/96 [==============================] - 0s 287us/step - loss: 0.1893 - acc: 0.9688 - val_loss: 0.1842 - val_acc: 0.9583\n",
            "Epoch 130/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.1888 - acc: 0.9792 - val_loss: 0.1833 - val_acc: 0.9583\n",
            "Epoch 131/200\n",
            "96/96 [==============================] - 0s 325us/step - loss: 0.1865 - acc: 0.9792 - val_loss: 0.1844 - val_acc: 0.9583\n",
            "Epoch 132/200\n",
            "96/96 [==============================] - 0s 308us/step - loss: 0.1871 - acc: 0.9792 - val_loss: 0.1835 - val_acc: 0.9583\n",
            "Epoch 133/200\n",
            "96/96 [==============================] - 0s 312us/step - loss: 0.1836 - acc: 0.9792 - val_loss: 0.1780 - val_acc: 0.9583\n",
            "Epoch 134/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.1852 - acc: 0.9688 - val_loss: 0.1746 - val_acc: 0.9583\n",
            "Epoch 135/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.1833 - acc: 0.9792 - val_loss: 0.1832 - val_acc: 0.9583\n",
            "Epoch 136/200\n",
            "96/96 [==============================] - 0s 320us/step - loss: 0.1808 - acc: 0.9792 - val_loss: 0.1792 - val_acc: 0.9583\n",
            "Epoch 137/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.1795 - acc: 0.9792 - val_loss: 0.1785 - val_acc: 0.9583\n",
            "Epoch 138/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.1781 - acc: 0.9792 - val_loss: 0.1769 - val_acc: 0.9583\n",
            "Epoch 139/200\n",
            "96/96 [==============================] - 0s 315us/step - loss: 0.1769 - acc: 0.9792 - val_loss: 0.1755 - val_acc: 0.9583\n",
            "Epoch 140/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.1766 - acc: 0.9792 - val_loss: 0.1723 - val_acc: 0.9583\n",
            "Epoch 141/200\n",
            "96/96 [==============================] - 0s 331us/step - loss: 0.1765 - acc: 0.9792 - val_loss: 0.1720 - val_acc: 0.9583\n",
            "Epoch 142/200\n",
            "96/96 [==============================] - 0s 333us/step - loss: 0.1742 - acc: 0.9688 - val_loss: 0.1679 - val_acc: 0.9583\n",
            "Epoch 143/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.1755 - acc: 0.9792 - val_loss: 0.1720 - val_acc: 0.9583\n",
            "Epoch 144/200\n",
            "96/96 [==============================] - 0s 320us/step - loss: 0.1714 - acc: 0.9792 - val_loss: 0.1693 - val_acc: 0.9583\n",
            "Epoch 145/200\n",
            "96/96 [==============================] - 0s 332us/step - loss: 0.1713 - acc: 0.9792 - val_loss: 0.1661 - val_acc: 0.9583\n",
            "Epoch 146/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.1707 - acc: 0.9792 - val_loss: 0.1683 - val_acc: 0.9583\n",
            "Epoch 147/200\n",
            "96/96 [==============================] - 0s 302us/step - loss: 0.1690 - acc: 0.9792 - val_loss: 0.1638 - val_acc: 0.9583\n",
            "Epoch 148/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.1681 - acc: 0.9792 - val_loss: 0.1643 - val_acc: 0.9583\n",
            "Epoch 149/200\n",
            "96/96 [==============================] - 0s 308us/step - loss: 0.1680 - acc: 0.9792 - val_loss: 0.1663 - val_acc: 0.9583\n",
            "Epoch 150/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.1668 - acc: 0.9792 - val_loss: 0.1630 - val_acc: 0.9583\n",
            "Epoch 151/200\n",
            "96/96 [==============================] - 0s 345us/step - loss: 0.1651 - acc: 0.9792 - val_loss: 0.1617 - val_acc: 0.9583\n",
            "Epoch 152/200\n",
            "96/96 [==============================] - 0s 313us/step - loss: 0.1657 - acc: 0.9792 - val_loss: 0.1627 - val_acc: 0.9583\n",
            "Epoch 153/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.1642 - acc: 0.9792 - val_loss: 0.1621 - val_acc: 0.9583\n",
            "Epoch 154/200\n",
            "96/96 [==============================] - 0s 309us/step - loss: 0.1620 - acc: 0.9792 - val_loss: 0.1584 - val_acc: 0.9583\n",
            "Epoch 155/200\n",
            "96/96 [==============================] - 0s 320us/step - loss: 0.1616 - acc: 0.9792 - val_loss: 0.1556 - val_acc: 0.9583\n",
            "Epoch 156/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.1614 - acc: 0.9792 - val_loss: 0.1556 - val_acc: 0.9583\n",
            "Epoch 157/200\n",
            "96/96 [==============================] - 0s 327us/step - loss: 0.1603 - acc: 0.9792 - val_loss: 0.1549 - val_acc: 0.9583\n",
            "Epoch 158/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.1602 - acc: 0.9688 - val_loss: 0.1531 - val_acc: 0.9583\n",
            "Epoch 159/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.1592 - acc: 0.9792 - val_loss: 0.1547 - val_acc: 0.9583\n",
            "Epoch 160/200\n",
            "96/96 [==============================] - 0s 320us/step - loss: 0.1576 - acc: 0.9792 - val_loss: 0.1552 - val_acc: 0.9583\n",
            "Epoch 161/200\n",
            "96/96 [==============================] - 0s 323us/step - loss: 0.1564 - acc: 0.9792 - val_loss: 0.1546 - val_acc: 0.9583\n",
            "Epoch 162/200\n",
            "96/96 [==============================] - 0s 335us/step - loss: 0.1559 - acc: 0.9792 - val_loss: 0.1550 - val_acc: 0.9583\n",
            "Epoch 163/200\n",
            "96/96 [==============================] - 0s 308us/step - loss: 0.1552 - acc: 0.9792 - val_loss: 0.1560 - val_acc: 0.9583\n",
            "Epoch 164/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.1563 - acc: 0.9792 - val_loss: 0.1557 - val_acc: 0.9583\n",
            "Epoch 165/200\n",
            "96/96 [==============================] - 0s 318us/step - loss: 0.1529 - acc: 0.9792 - val_loss: 0.1494 - val_acc: 0.9583\n",
            "Epoch 166/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.1533 - acc: 0.9792 - val_loss: 0.1498 - val_acc: 0.9583\n",
            "Epoch 167/200\n",
            "96/96 [==============================] - 0s 322us/step - loss: 0.1514 - acc: 0.9792 - val_loss: 0.1498 - val_acc: 0.9583\n",
            "Epoch 168/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.1515 - acc: 0.9792 - val_loss: 0.1498 - val_acc: 0.9583\n",
            "Epoch 169/200\n",
            "96/96 [==============================] - 0s 320us/step - loss: 0.1509 - acc: 0.9792 - val_loss: 0.1462 - val_acc: 0.9583\n",
            "Epoch 170/200\n",
            "96/96 [==============================] - 0s 336us/step - loss: 0.1501 - acc: 0.9792 - val_loss: 0.1462 - val_acc: 0.9583\n",
            "Epoch 171/200\n",
            "96/96 [==============================] - 0s 323us/step - loss: 0.1496 - acc: 0.9688 - val_loss: 0.1432 - val_acc: 0.9583\n",
            "Epoch 172/200\n",
            "96/96 [==============================] - 0s 336us/step - loss: 0.1492 - acc: 0.9688 - val_loss: 0.1417 - val_acc: 0.9583\n",
            "Epoch 173/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.1480 - acc: 0.9792 - val_loss: 0.1424 - val_acc: 0.9583\n",
            "Epoch 174/200\n",
            "96/96 [==============================] - 0s 314us/step - loss: 0.1460 - acc: 0.9792 - val_loss: 0.1454 - val_acc: 0.9583\n",
            "Epoch 175/200\n",
            "96/96 [==============================] - 0s 311us/step - loss: 0.1458 - acc: 0.9792 - val_loss: 0.1481 - val_acc: 0.9583\n",
            "Epoch 176/200\n",
            "96/96 [==============================] - 0s 298us/step - loss: 0.1460 - acc: 0.9792 - val_loss: 0.1446 - val_acc: 0.9583\n",
            "Epoch 177/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.1451 - acc: 0.9792 - val_loss: 0.1429 - val_acc: 0.9583\n",
            "Epoch 178/200\n",
            "96/96 [==============================] - 0s 319us/step - loss: 0.1440 - acc: 0.9792 - val_loss: 0.1402 - val_acc: 0.9583\n",
            "Epoch 179/200\n",
            "96/96 [==============================] - 0s 318us/step - loss: 0.1461 - acc: 0.9688 - val_loss: 0.1370 - val_acc: 0.9583\n",
            "Epoch 180/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.1427 - acc: 0.9792 - val_loss: 0.1433 - val_acc: 0.9583\n",
            "Epoch 181/200\n",
            "96/96 [==============================] - 0s 316us/step - loss: 0.1421 - acc: 0.9792 - val_loss: 0.1394 - val_acc: 0.9583\n",
            "Epoch 182/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.1425 - acc: 0.9792 - val_loss: 0.1377 - val_acc: 0.9583\n",
            "Epoch 183/200\n",
            "96/96 [==============================] - 0s 312us/step - loss: 0.1411 - acc: 0.9792 - val_loss: 0.1380 - val_acc: 0.9583\n",
            "Epoch 184/200\n",
            "96/96 [==============================] - 0s 312us/step - loss: 0.1404 - acc: 0.9792 - val_loss: 0.1423 - val_acc: 0.9583\n",
            "Epoch 185/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.1422 - acc: 0.9792 - val_loss: 0.1365 - val_acc: 0.9583\n",
            "Epoch 186/200\n",
            "96/96 [==============================] - 0s 311us/step - loss: 0.1392 - acc: 0.9792 - val_loss: 0.1398 - val_acc: 0.9583\n",
            "Epoch 187/200\n",
            "96/96 [==============================] - 0s 317us/step - loss: 0.1383 - acc: 0.9792 - val_loss: 0.1355 - val_acc: 0.9583\n",
            "Epoch 188/200\n",
            "96/96 [==============================] - 0s 349us/step - loss: 0.1380 - acc: 0.9792 - val_loss: 0.1347 - val_acc: 0.9583\n",
            "Epoch 189/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.1375 - acc: 0.9792 - val_loss: 0.1358 - val_acc: 0.9583\n",
            "Epoch 190/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.1365 - acc: 0.9792 - val_loss: 0.1343 - val_acc: 0.9583\n",
            "Epoch 191/200\n",
            "96/96 [==============================] - 0s 317us/step - loss: 0.1364 - acc: 0.9792 - val_loss: 0.1325 - val_acc: 0.9583\n",
            "Epoch 192/200\n",
            "96/96 [==============================] - 0s 322us/step - loss: 0.1350 - acc: 0.9792 - val_loss: 0.1313 - val_acc: 0.9583\n",
            "Epoch 193/200\n",
            "96/96 [==============================] - 0s 315us/step - loss: 0.1351 - acc: 0.9792 - val_loss: 0.1304 - val_acc: 0.9583\n",
            "Epoch 194/200\n",
            "96/96 [==============================] - 0s 309us/step - loss: 0.1365 - acc: 0.9688 - val_loss: 0.1293 - val_acc: 0.9583\n",
            "Epoch 195/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.1343 - acc: 0.9792 - val_loss: 0.1310 - val_acc: 0.9583\n",
            "Epoch 196/200\n",
            "96/96 [==============================] - 0s 320us/step - loss: 0.1338 - acc: 0.9792 - val_loss: 0.1322 - val_acc: 0.9583\n",
            "Epoch 197/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.1342 - acc: 0.9792 - val_loss: 0.1305 - val_acc: 0.9583\n",
            "Epoch 198/200\n",
            "96/96 [==============================] - 0s 337us/step - loss: 0.1327 - acc: 0.9792 - val_loss: 0.1273 - val_acc: 0.9583\n",
            "Epoch 199/200\n",
            "96/96 [==============================] - 0s 308us/step - loss: 0.1315 - acc: 0.9792 - val_loss: 0.1273 - val_acc: 0.9583\n",
            "Epoch 200/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.1321 - acc: 0.9792 - val_loss: 0.1252 - val_acc: 0.9583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHreB--UHEuB",
        "colab_type": "text"
      },
      "source": [
        "### Examining the plot\n",
        "\n",
        "In this model loss plot we can see that the model's loss gradually drops at it reaches 200 epochs and that our training and validation data loss do not deviate from each other meaning there is no overfitting present.\n",
        "\n",
        "We can also see that the accuracy of the training and validation data sets increase in accuracy in a similar fashion meaning which also indicate that there is no significant overfitting in our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwYPK696zTqu",
        "colab_type": "code",
        "outputId": "a16f3d31-50fd-48ed-ad65-7fc5eb8a3619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "def plot_acc_loss(history):\n",
        "    f, (ax1, ax2) = plt.subplots(2,1, figsize=(10,10))\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax1.plot(history.history['loss'])\n",
        "    ax1.plot(history.history['val_loss'])\n",
        "    ax1.set_title('model loss')\n",
        "    ax1.legend(['train', 'val'], loc='upper left')\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax2.plot(history.history['acc'])\n",
        "    ax2.plot(history.history['val_acc'])\n",
        "    ax2.set_title('model accuracy')\n",
        "    ax2.set_xlabel('epoch')\n",
        "    ax2.legend(['train', 'val'], loc='upper left')\n",
        "    \n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.show()\n",
        "    \n",
        "plot_acc_loss(history)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJcCAYAAAA7Pup5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOfL/A/cNxcmeAtEIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw2wWtw5zTqy",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model\n",
        "Now that we have trained our model, we can evaluate it's predictive performance on our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQtZLcOdzTq0",
        "colab_type": "code",
        "outputId": "f4c38e1c-d01d-4d81-9cd6-858b11ed851d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"\\n\\n{0}: {1:.2f}%\".format(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 0s 38us/step\n",
            "\n",
            "\n",
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2ihtRTBQ9R",
        "colab_type": "text"
      },
      "source": [
        "Our accuracy across our test set is 96.67% meaning that if we were to use this model on new data from the same Iris dataset, it would correctly classify the Iris species 96.67% of the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnnHSuWHBmIT",
        "colab_type": "text"
      },
      "source": [
        "### The Confusion Matrix\n",
        "\n",
        "A confusion matrix is useful for describing the performance of a classification model. Instead of seeing generalised accuracy, we're able to look how each individual classification performs. \n",
        "\n",
        "In this case we can see that a sample of Versicolor was incorrectly classified as Virginica which we could try to improve in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEnF0buSzTq4",
        "colab_type": "code",
        "outputId": "f866dbea-7fcf-4c05-daca-c2de76e0edc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "def draw_confusion_matrix(true, pred, labels):\n",
        "  \"\"\"\n",
        "  Drawing confusion matrix\n",
        "  \"\"\"\n",
        "  cm = metrics.confusion_matrix(true, pred, labels)\n",
        "  ax = plt.subplot()\n",
        "  sns.heatmap(cm, annot=True, ax=ax)\n",
        "  ax.set_xticklabels(['Setosa', 'Versicolor', 'Virginica']+labels)\n",
        "  ax.set_yticklabels(['Setosa', 'Versicolor', 'Virginica']+labels)\n",
        "  ax.set_xlabel(\"Predicted Classification\")\n",
        "  ax.set_ylabel(\"True Classification\")\n",
        "  plt.show()\n",
        "  return cm\n",
        "\n",
        "y_pred = model.predict_classes(X_test)\n",
        "y_test_encoded = [np.argmax(i) for i in y_test] # Reverse one hot encoded to label encoded\n",
        "matrix = draw_confusion_matrix(y_test_encoded, y_pred, [0,1,2]) #[setosa,versicolor, virginica]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNjMrKFfQZmYF5QrazKyg/j87nLaA4JTYlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhOFX6LUzTrD",
        "colab_type": "code",
        "outputId": "5a5e8af6-8a6e-44ec-90f0-c41650637d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"acc: {0:.2f}%\".format(np.sum(np.diag(matrix))*100/np.sum(matrix)))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHe0CcqcsO1Q",
        "colab_type": "text"
      },
      "source": [
        "# Key Points\n",
        "\n",
        "\n",
        "*   Created a neural network to solve multiclass classification problem\n",
        "*   \"One hot encoded\" to categorise string target variable\n",
        "*  Different loss functions for different classfication problems\n",
        "* Confusion matrix and model improvements\n",
        "\n",
        "\n"
      ]
    }
  ]
}