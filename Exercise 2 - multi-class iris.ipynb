{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 2 - multi-class iris.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UoA-eResearch/deep-learning-tutorial-2019/blob/master/Exercise%202%20-%20multi-class%20iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPQTvjnTzTqM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2: The Iris Dataset\n",
        "In this exercise we will create a neural network to classify 3 different types of Iris (Setosa, Versicolor and Virginica) based on their sepal length, sepal width, petal length and petal width.\n",
        "\n",
        "![Irises](http://dataaspirant.com/wp-content/uploads/2017/01/irises.png)\n",
        "\n",
        "This is a multi class classification problem. It is similar to the Pima Indian's binary classification exercise, but with three classes to predict instead of two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9VrMNin1Yi",
        "colab_type": "text"
      },
      "source": [
        "### Q: How many steps are there in creating a neural network model? Please list those steps\n",
        "\n",
        "*answer...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B9pUqCzTqO",
        "colab_type": "text"
      },
      "source": [
        "### Import dependencies\n",
        "Start by importing the dependencies we will need for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB8CJHppzTqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxNqXnJTzTqY",
        "colab_type": "text"
      },
      "source": [
        "### Import data\n",
        "The Iris dataset contains four features from 150 different Iris flowers. The features in the dataset are described below.\n",
        "\n",
        "* Sepal length (cm)\n",
        "* Sepal width (cm)\n",
        "* Petal length (cm)\n",
        "* Petal width (cm)\n",
        "* Class: Iris setosa, Iris versicolor or Iris virginica\n",
        "\n",
        "Sepals are the part of a flower that protect and support the petals. The petals surround the reproductive parts of the flower.\n",
        "\n",
        "![Iris labeled](http://terpconnect.umd.edu/~petersd/666/html/iris_with_labels.jpg)\n",
        "\n",
        "A snapshot of the dataset is illustrated below (not in order).\n",
        "\n",
        "|Sepal Length|Sepal Width|Petal Length|Petal Width|Class|\n",
        "|---|---|---|---|-----------|\n",
        "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
        "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
        "|7.0|3.2|4.7|1.4|Iris-versicolor|\n",
        "|6.4|3.2|4.5|1.5|Iris-versicolor|\n",
        "|6.3|3.3|6.0|2.5|Iris-virginica|\n",
        "|5.8|2.7|5.1|1.9|Iris-virginica|\n",
        "\n",
        "To load this data into memory, use the `np.loadtxt` function. The data type (`dtype`) is set to `str` because our input data is a mix of numbers and strings. This will be dealt with when we split the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wYz6SEDzTqY",
        "colab_type": "code",
        "outputId": "6cfa8134-a5b6-4e3e-8848-6b9dc216edb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data = np.loadtxt('https://raw.githubusercontent.com/UoA-eResearch/deep-learning-tutorial-2019/master/data/iris.csv', delimiter=\",\", dtype=str)\n",
        "print(data[:6]) #Show the first 6 rows"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['5.1' '3.5' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.9' '3.0' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.7' '3.2' '1.3' '0.2' 'Iris-setosa']\n",
            " ['4.6' '3.1' '1.5' '0.2' 'Iris-setosa']\n",
            " ['5.0' '3.6' '1.4' '0.2' 'Iris-setosa']\n",
            " ['5.4' '3.9' '1.7' '0.4' 'Iris-setosa']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGLO13AQzTqb",
        "colab_type": "text"
      },
      "source": [
        "Separate the data into input (X) and output (y) variables.\n",
        "\n",
        "Note that we convert the input data into floats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-EcR4awzTqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[:, 0:4].astype(float)\n",
        "y = data[:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zYDMAbzTqd",
        "colab_type": "text"
      },
      "source": [
        "If you look carefully at the target values, you will notice that they are strings, i.e. 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'.\n",
        "\n",
        "**Keras needs numbers or matrices to work with, so we will need to reformat the target values.**\n",
        "\n",
        "The problem with converting the class values to numbers (e.g. 'Iris-setosa' becomes 0, 'Iris-versicolor' 1 etc) is that it implies that the target values are ordinal. That is, 'Iris-setosa' is somehow less than 'Iris-versicolor', which is not the case for this dataset.\n",
        "\n",
        "A better way to represent classes in a multi-class classification problem, is to 'one hot encode' the target values. An example is shown below. A matrix of zeros is generated. Each row corresponds to a sample and each column corresponds to a particular class. A 1 is placed into the column to incidicate the class that it belongs too.\n",
        "\n",
        "|Iris-setosa|Iris-versicolor|Iris-virginica|\n",
        "|---|---|---|\n",
        "|1|0|0|\n",
        "|0|1|0|\n",
        "|0|0|1|\n",
        "\n",
        "One hot encoding is a two step process. First encode the target values (y) into an array of numbers using the `LabelEncoder` from scikit-learn and then one hot encode the numbers with the `np_utils.to_categorical` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmReXRywzTqe",
        "colab_type": "code",
        "outputId": "7be74f3f-f443-40a4-ed93-124576aacc83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_encoded = LabelEncoder().fit(y).transform(y) # Convert the classes into numbers\n",
        "y_encoded[45:55]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQgfvZcfzTqi",
        "colab_type": "code",
        "outputId": "b42d13d8-6d75-4610-a6f2-ddffb6f2279b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_one_hot_encoded = np_utils.to_categorical(y_encoded) # One hot encode the numbers\n",
        "y_one_hot_encoded[45:55]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMbd6-LV9Rm_",
        "colab_type": "text"
      },
      "source": [
        "### Set seed\n",
        "Set a seed value so that when we repeatedly run our code we will get the same result. Using the same seed is important when you want to compare algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvjmpbYM9UN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9s47Jx9zTqk",
        "colab_type": "text"
      },
      "source": [
        "Like the previous exercise, use the `train_test_split` function from scikit-learn to split the input and target data into training, validation and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qdeRm6LzTql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_encoded, test_size=0.2, random_state=seed)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gp1FcnQzTqn",
        "colab_type": "text"
      },
      "source": [
        "### Create the model\n",
        "The code snippet below creates a very basic neural network model, with three layers: an input layer, a hidden layer and an output layer.\n",
        "\n",
        "The first layer is a fully connected `Dense` layer. We use four neurons in the hidden layer and have 4 input neurons for the 4 features.\n",
        "\n",
        "The last layer has 3 neurons, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG9oXx6dzTqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=4, activation='relu', kernel_initializer='normal'))\n",
        "model.add(Dense(3, activation='sigmoid', kernel_initializer='normal'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McwgpeyfzTqp",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "We then compile the model. The loss function is set to `categorical_crossentropy` (different from the loss function used in the binary classification exercise) because we are performing multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F86R20yJzTqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr-3q6CEzTqs",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "Now that we have compiled the model, we can train it with the data we prepared earlier. We are using more epochs but a smaller batch size than the previous exercise.\n",
        "\n",
        "To see the model training history in text, just don't include `verbose=0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ohIS-DzTqs",
        "colab_type": "code",
        "outputId": "29377067-3bb8-4536-c0f4-d6fae382b105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=5)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 96 samples, validate on 24 samples\n",
            "Epoch 1/200\n",
            "96/96 [==============================] - 0s 3ms/step - loss: 1.0998 - acc: 0.3438 - val_loss: 1.0979 - val_acc: 0.4167\n",
            "Epoch 2/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 1.0972 - acc: 0.5833 - val_loss: 1.0968 - val_acc: 0.6667\n",
            "Epoch 3/200\n",
            "96/96 [==============================] - 0s 325us/step - loss: 1.0953 - acc: 0.6458 - val_loss: 1.0951 - val_acc: 0.6250\n",
            "Epoch 4/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 1.0927 - acc: 0.3854 - val_loss: 1.0932 - val_acc: 0.2500\n",
            "Epoch 5/200\n",
            "96/96 [==============================] - 0s 315us/step - loss: 1.0888 - acc: 0.3438 - val_loss: 1.0900 - val_acc: 0.2500\n",
            "Epoch 6/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 1.0836 - acc: 0.3438 - val_loss: 1.0856 - val_acc: 0.2500\n",
            "Epoch 7/200\n",
            "96/96 [==============================] - 0s 244us/step - loss: 1.0771 - acc: 0.3854 - val_loss: 1.0793 - val_acc: 0.4167\n",
            "Epoch 8/200\n",
            "96/96 [==============================] - 0s 316us/step - loss: 1.0690 - acc: 0.5625 - val_loss: 1.0708 - val_acc: 0.6250\n",
            "Epoch 9/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 1.0587 - acc: 0.6458 - val_loss: 1.0613 - val_acc: 0.6667\n",
            "Epoch 10/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 1.0471 - acc: 0.6563 - val_loss: 1.0500 - val_acc: 0.6667\n",
            "Epoch 11/200\n",
            "96/96 [==============================] - 0s 316us/step - loss: 1.0337 - acc: 0.6875 - val_loss: 1.0357 - val_acc: 0.6667\n",
            "Epoch 12/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 1.0181 - acc: 0.6875 - val_loss: 1.0203 - val_acc: 0.6667\n",
            "Epoch 13/200\n",
            "96/96 [==============================] - 0s 338us/step - loss: 1.0001 - acc: 0.6875 - val_loss: 1.0004 - val_acc: 0.6667\n",
            "Epoch 14/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.9806 - acc: 0.6875 - val_loss: 0.9816 - val_acc: 0.6667\n",
            "Epoch 15/200\n",
            "96/96 [==============================] - 0s 265us/step - loss: 0.9589 - acc: 0.6875 - val_loss: 0.9599 - val_acc: 0.6667\n",
            "Epoch 16/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.9379 - acc: 0.6875 - val_loss: 0.9369 - val_acc: 0.6667\n",
            "Epoch 17/200\n",
            "96/96 [==============================] - 0s 260us/step - loss: 0.9173 - acc: 0.6875 - val_loss: 0.9173 - val_acc: 0.6667\n",
            "Epoch 18/200\n",
            "96/96 [==============================] - 0s 325us/step - loss: 0.8927 - acc: 0.6875 - val_loss: 0.8920 - val_acc: 0.6667\n",
            "Epoch 19/200\n",
            "96/96 [==============================] - 0s 316us/step - loss: 0.8704 - acc: 0.6875 - val_loss: 0.8681 - val_acc: 0.6667\n",
            "Epoch 20/200\n",
            "96/96 [==============================] - 0s 355us/step - loss: 0.8476 - acc: 0.6875 - val_loss: 0.8432 - val_acc: 0.6667\n",
            "Epoch 21/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.8254 - acc: 0.6875 - val_loss: 0.8196 - val_acc: 0.6667\n",
            "Epoch 22/200\n",
            "96/96 [==============================] - 0s 317us/step - loss: 0.8030 - acc: 0.6875 - val_loss: 0.7986 - val_acc: 0.6667\n",
            "Epoch 23/200\n",
            "96/96 [==============================] - 0s 387us/step - loss: 0.7817 - acc: 0.6875 - val_loss: 0.7747 - val_acc: 0.6667\n",
            "Epoch 24/200\n",
            "96/96 [==============================] - 0s 326us/step - loss: 0.7594 - acc: 0.6875 - val_loss: 0.7509 - val_acc: 0.6667\n",
            "Epoch 25/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.7384 - acc: 0.6875 - val_loss: 0.7299 - val_acc: 0.6667\n",
            "Epoch 26/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.7188 - acc: 0.6875 - val_loss: 0.7068 - val_acc: 0.6667\n",
            "Epoch 27/200\n",
            "96/96 [==============================] - 0s 371us/step - loss: 0.6995 - acc: 0.6875 - val_loss: 0.6901 - val_acc: 0.6667\n",
            "Epoch 28/200\n",
            "96/96 [==============================] - 0s 384us/step - loss: 0.6799 - acc: 0.6875 - val_loss: 0.6672 - val_acc: 0.6667\n",
            "Epoch 29/200\n",
            "96/96 [==============================] - 0s 363us/step - loss: 0.6625 - acc: 0.6875 - val_loss: 0.6504 - val_acc: 0.6667\n",
            "Epoch 30/200\n",
            "96/96 [==============================] - 0s 342us/step - loss: 0.6443 - acc: 0.6875 - val_loss: 0.6309 - val_acc: 0.6667\n",
            "Epoch 31/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.6288 - acc: 0.6875 - val_loss: 0.6150 - val_acc: 0.7083\n",
            "Epoch 32/200\n",
            "96/96 [==============================] - 0s 298us/step - loss: 0.6134 - acc: 0.6875 - val_loss: 0.5961 - val_acc: 0.7083\n",
            "Epoch 33/200\n",
            "96/96 [==============================] - 0s 336us/step - loss: 0.5979 - acc: 0.7083 - val_loss: 0.5810 - val_acc: 0.7083\n",
            "Epoch 34/200\n",
            "96/96 [==============================] - 0s 322us/step - loss: 0.5835 - acc: 0.7083 - val_loss: 0.5661 - val_acc: 0.7083\n",
            "Epoch 35/200\n",
            "96/96 [==============================] - 0s 317us/step - loss: 0.5693 - acc: 0.7292 - val_loss: 0.5493 - val_acc: 0.7083\n",
            "Epoch 36/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.5559 - acc: 0.8125 - val_loss: 0.5342 - val_acc: 0.7917\n",
            "Epoch 37/200\n",
            "96/96 [==============================] - 0s 337us/step - loss: 0.5434 - acc: 0.7708 - val_loss: 0.5247 - val_acc: 0.7083\n",
            "Epoch 38/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.5313 - acc: 0.8333 - val_loss: 0.5096 - val_acc: 0.8333\n",
            "Epoch 39/200\n",
            "96/96 [==============================] - 0s 321us/step - loss: 0.5196 - acc: 0.8542 - val_loss: 0.4989 - val_acc: 0.8333\n",
            "Epoch 40/200\n",
            "96/96 [==============================] - 0s 277us/step - loss: 0.5085 - acc: 0.8854 - val_loss: 0.4849 - val_acc: 0.9167\n",
            "Epoch 41/200\n",
            "96/96 [==============================] - 0s 265us/step - loss: 0.4973 - acc: 0.9167 - val_loss: 0.4751 - val_acc: 0.9167\n",
            "Epoch 42/200\n",
            "96/96 [==============================] - 0s 358us/step - loss: 0.4891 - acc: 0.8750 - val_loss: 0.4671 - val_acc: 0.8333\n",
            "Epoch 43/200\n",
            "96/96 [==============================] - 0s 323us/step - loss: 0.4781 - acc: 0.8750 - val_loss: 0.4579 - val_acc: 0.8333\n",
            "Epoch 44/200\n",
            "96/96 [==============================] - 0s 384us/step - loss: 0.4680 - acc: 0.8958 - val_loss: 0.4468 - val_acc: 0.9167\n",
            "Epoch 45/200\n",
            "96/96 [==============================] - 0s 317us/step - loss: 0.4589 - acc: 0.9271 - val_loss: 0.4374 - val_acc: 0.9167\n",
            "Epoch 46/200\n",
            "96/96 [==============================] - 0s 349us/step - loss: 0.4501 - acc: 0.9688 - val_loss: 0.4287 - val_acc: 0.9167\n",
            "Epoch 47/200\n",
            "96/96 [==============================] - 0s 347us/step - loss: 0.4416 - acc: 0.9375 - val_loss: 0.4216 - val_acc: 0.9167\n",
            "Epoch 48/200\n",
            "96/96 [==============================] - 0s 278us/step - loss: 0.4339 - acc: 0.9167 - val_loss: 0.4139 - val_acc: 0.9167\n",
            "Epoch 49/200\n",
            "96/96 [==============================] - 0s 278us/step - loss: 0.4270 - acc: 0.8854 - val_loss: 0.4087 - val_acc: 0.9167\n",
            "Epoch 50/200\n",
            "96/96 [==============================] - 0s 324us/step - loss: 0.4176 - acc: 0.9271 - val_loss: 0.3982 - val_acc: 0.9583\n",
            "Epoch 51/200\n",
            "96/96 [==============================] - 0s 327us/step - loss: 0.4103 - acc: 0.9792 - val_loss: 0.3903 - val_acc: 0.9583\n",
            "Epoch 52/200\n",
            "96/96 [==============================] - 0s 311us/step - loss: 0.4037 - acc: 0.9792 - val_loss: 0.3847 - val_acc: 0.9583\n",
            "Epoch 53/200\n",
            "96/96 [==============================] - 0s 312us/step - loss: 0.3992 - acc: 0.9792 - val_loss: 0.3754 - val_acc: 0.9583\n",
            "Epoch 54/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.3896 - acc: 0.9792 - val_loss: 0.3737 - val_acc: 0.9583\n",
            "Epoch 55/200\n",
            "96/96 [==============================] - 0s 268us/step - loss: 0.3843 - acc: 0.9583 - val_loss: 0.3691 - val_acc: 0.9583\n",
            "Epoch 56/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.3797 - acc: 0.9792 - val_loss: 0.3586 - val_acc: 0.9583\n",
            "Epoch 57/200\n",
            "96/96 [==============================] - 0s 274us/step - loss: 0.3717 - acc: 0.9792 - val_loss: 0.3579 - val_acc: 0.9583\n",
            "Epoch 58/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.3663 - acc: 0.9792 - val_loss: 0.3509 - val_acc: 0.9583\n",
            "Epoch 59/200\n",
            "96/96 [==============================] - 0s 340us/step - loss: 0.3611 - acc: 0.9792 - val_loss: 0.3444 - val_acc: 0.9583\n",
            "Epoch 60/200\n",
            "96/96 [==============================] - 0s 315us/step - loss: 0.3560 - acc: 0.9792 - val_loss: 0.3438 - val_acc: 0.9583\n",
            "Epoch 61/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.3518 - acc: 0.9792 - val_loss: 0.3348 - val_acc: 0.9583\n",
            "Epoch 62/200\n",
            "96/96 [==============================] - 0s 313us/step - loss: 0.3475 - acc: 0.9792 - val_loss: 0.3309 - val_acc: 0.9583\n",
            "Epoch 63/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.3415 - acc: 0.9792 - val_loss: 0.3264 - val_acc: 0.9583\n",
            "Epoch 64/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.3388 - acc: 0.9792 - val_loss: 0.3223 - val_acc: 0.9583\n",
            "Epoch 65/200\n",
            "96/96 [==============================] - 0s 287us/step - loss: 0.3324 - acc: 0.9792 - val_loss: 0.3199 - val_acc: 0.9583\n",
            "Epoch 66/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.3288 - acc: 0.9792 - val_loss: 0.3190 - val_acc: 0.9583\n",
            "Epoch 67/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.3239 - acc: 0.9792 - val_loss: 0.3099 - val_acc: 0.9583\n",
            "Epoch 68/200\n",
            "96/96 [==============================] - 0s 287us/step - loss: 0.3222 - acc: 0.9792 - val_loss: 0.3093 - val_acc: 0.9583\n",
            "Epoch 69/200\n",
            "96/96 [==============================] - 0s 306us/step - loss: 0.3165 - acc: 0.9792 - val_loss: 0.3048 - val_acc: 0.9583\n",
            "Epoch 70/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.3152 - acc: 0.9792 - val_loss: 0.3041 - val_acc: 0.9583\n",
            "Epoch 71/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.3088 - acc: 0.9792 - val_loss: 0.2961 - val_acc: 0.9583\n",
            "Epoch 72/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.3069 - acc: 0.9792 - val_loss: 0.2923 - val_acc: 0.9583\n",
            "Epoch 73/200\n",
            "96/96 [==============================] - 0s 271us/step - loss: 0.3028 - acc: 0.9792 - val_loss: 0.2912 - val_acc: 0.9583\n",
            "Epoch 74/200\n",
            "96/96 [==============================] - 0s 278us/step - loss: 0.3037 - acc: 0.9792 - val_loss: 0.2946 - val_acc: 0.9583\n",
            "Epoch 75/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.2964 - acc: 0.9792 - val_loss: 0.2862 - val_acc: 0.9583\n",
            "Epoch 76/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.2923 - acc: 0.9792 - val_loss: 0.2857 - val_acc: 0.9583\n",
            "Epoch 77/200\n",
            "96/96 [==============================] - 0s 261us/step - loss: 0.2897 - acc: 0.9792 - val_loss: 0.2845 - val_acc: 0.9583\n",
            "Epoch 78/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.2880 - acc: 0.9792 - val_loss: 0.2819 - val_acc: 0.9583\n",
            "Epoch 79/200\n",
            "96/96 [==============================] - 0s 259us/step - loss: 0.2835 - acc: 0.9792 - val_loss: 0.2746 - val_acc: 0.9583\n",
            "Epoch 80/200\n",
            "96/96 [==============================] - 0s 326us/step - loss: 0.2815 - acc: 0.9792 - val_loss: 0.2718 - val_acc: 0.9583\n",
            "Epoch 81/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.2782 - acc: 0.9792 - val_loss: 0.2700 - val_acc: 0.9583\n",
            "Epoch 82/200\n",
            "96/96 [==============================] - 0s 280us/step - loss: 0.2767 - acc: 0.9792 - val_loss: 0.2712 - val_acc: 0.9583\n",
            "Epoch 83/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.2734 - acc: 0.9792 - val_loss: 0.2670 - val_acc: 0.9583\n",
            "Epoch 84/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.2720 - acc: 0.9792 - val_loss: 0.2668 - val_acc: 0.9583\n",
            "Epoch 85/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.2679 - acc: 0.9792 - val_loss: 0.2594 - val_acc: 0.9583\n",
            "Epoch 86/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.2660 - acc: 0.9792 - val_loss: 0.2547 - val_acc: 0.9583\n",
            "Epoch 87/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.2658 - acc: 0.9792 - val_loss: 0.2563 - val_acc: 0.9583\n",
            "Epoch 88/200\n",
            "96/96 [==============================] - 0s 320us/step - loss: 0.2639 - acc: 0.9792 - val_loss: 0.2510 - val_acc: 0.9583\n",
            "Epoch 89/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.2589 - acc: 0.9792 - val_loss: 0.2531 - val_acc: 0.9583\n",
            "Epoch 90/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.2560 - acc: 0.9792 - val_loss: 0.2480 - val_acc: 0.9583\n",
            "Epoch 91/200\n",
            "96/96 [==============================] - 0s 341us/step - loss: 0.2538 - acc: 0.9792 - val_loss: 0.2497 - val_acc: 0.9583\n",
            "Epoch 92/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.2516 - acc: 0.9792 - val_loss: 0.2488 - val_acc: 0.9583\n",
            "Epoch 93/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.2510 - acc: 0.9792 - val_loss: 0.2480 - val_acc: 0.9583\n",
            "Epoch 94/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.2471 - acc: 0.9792 - val_loss: 0.2397 - val_acc: 0.9583\n",
            "Epoch 95/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.2444 - acc: 0.9792 - val_loss: 0.2384 - val_acc: 0.9583\n",
            "Epoch 96/200\n",
            "96/96 [==============================] - 0s 298us/step - loss: 0.2445 - acc: 0.9792 - val_loss: 0.2395 - val_acc: 0.9583\n",
            "Epoch 97/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.2409 - acc: 0.9792 - val_loss: 0.2355 - val_acc: 0.9583\n",
            "Epoch 98/200\n",
            "96/96 [==============================] - 0s 280us/step - loss: 0.2388 - acc: 0.9792 - val_loss: 0.2308 - val_acc: 0.9583\n",
            "Epoch 99/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.2362 - acc: 0.9792 - val_loss: 0.2307 - val_acc: 0.9583\n",
            "Epoch 100/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.2358 - acc: 0.9792 - val_loss: 0.2323 - val_acc: 0.9583\n",
            "Epoch 101/200\n",
            "96/96 [==============================] - 0s 316us/step - loss: 0.2334 - acc: 0.9792 - val_loss: 0.2284 - val_acc: 0.9583\n",
            "Epoch 102/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.2303 - acc: 0.9792 - val_loss: 0.2259 - val_acc: 0.9583\n",
            "Epoch 103/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.2331 - acc: 0.9688 - val_loss: 0.2201 - val_acc: 0.9583\n",
            "Epoch 104/200\n",
            "96/96 [==============================] - 0s 270us/step - loss: 0.2281 - acc: 0.9792 - val_loss: 0.2237 - val_acc: 0.9583\n",
            "Epoch 105/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.2255 - acc: 0.9792 - val_loss: 0.2198 - val_acc: 0.9583\n",
            "Epoch 106/200\n",
            "96/96 [==============================] - 0s 278us/step - loss: 0.2229 - acc: 0.9792 - val_loss: 0.2192 - val_acc: 0.9583\n",
            "Epoch 107/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.2231 - acc: 0.9792 - val_loss: 0.2208 - val_acc: 0.9583\n",
            "Epoch 108/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.2213 - acc: 0.9792 - val_loss: 0.2181 - val_acc: 0.9583\n",
            "Epoch 109/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.2193 - acc: 0.9792 - val_loss: 0.2145 - val_acc: 0.9583\n",
            "Epoch 110/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.2168 - acc: 0.9792 - val_loss: 0.2125 - val_acc: 0.9583\n",
            "Epoch 111/200\n",
            "96/96 [==============================] - 0s 269us/step - loss: 0.2151 - acc: 0.9792 - val_loss: 0.2090 - val_acc: 0.9583\n",
            "Epoch 112/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.2152 - acc: 0.9792 - val_loss: 0.2106 - val_acc: 0.9583\n",
            "Epoch 113/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.2125 - acc: 0.9792 - val_loss: 0.2078 - val_acc: 0.9583\n",
            "Epoch 114/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.2103 - acc: 0.9792 - val_loss: 0.2064 - val_acc: 0.9583\n",
            "Epoch 115/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.2096 - acc: 0.9792 - val_loss: 0.2072 - val_acc: 0.9583\n",
            "Epoch 116/200\n",
            "96/96 [==============================] - 0s 287us/step - loss: 0.2058 - acc: 0.9792 - val_loss: 0.1997 - val_acc: 0.9583\n",
            "Epoch 117/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.2058 - acc: 0.9792 - val_loss: 0.2001 - val_acc: 0.9583\n",
            "Epoch 118/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.2039 - acc: 0.9792 - val_loss: 0.1983 - val_acc: 0.9583\n",
            "Epoch 119/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.2025 - acc: 0.9792 - val_loss: 0.2018 - val_acc: 0.9583\n",
            "Epoch 120/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.2020 - acc: 0.9792 - val_loss: 0.1977 - val_acc: 0.9583\n",
            "Epoch 121/200\n",
            "96/96 [==============================] - 0s 316us/step - loss: 0.1992 - acc: 0.9792 - val_loss: 0.1995 - val_acc: 0.9583\n",
            "Epoch 122/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.1988 - acc: 0.9792 - val_loss: 0.1963 - val_acc: 0.9583\n",
            "Epoch 123/200\n",
            "96/96 [==============================] - 0s 383us/step - loss: 0.1968 - acc: 0.9792 - val_loss: 0.1950 - val_acc: 0.9583\n",
            "Epoch 124/200\n",
            "96/96 [==============================] - 0s 270us/step - loss: 0.1973 - acc: 0.9792 - val_loss: 0.1999 - val_acc: 0.9583\n",
            "Epoch 125/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.1952 - acc: 0.9792 - val_loss: 0.1947 - val_acc: 0.9583\n",
            "Epoch 126/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.1954 - acc: 0.9792 - val_loss: 0.1845 - val_acc: 0.9583\n",
            "Epoch 127/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.1941 - acc: 0.9688 - val_loss: 0.1898 - val_acc: 0.9583\n",
            "Epoch 128/200\n",
            "96/96 [==============================] - 0s 277us/step - loss: 0.1905 - acc: 0.9792 - val_loss: 0.1835 - val_acc: 0.9583\n",
            "Epoch 129/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.1895 - acc: 0.9688 - val_loss: 0.1844 - val_acc: 0.9583\n",
            "Epoch 130/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.1889 - acc: 0.9792 - val_loss: 0.1835 - val_acc: 0.9583\n",
            "Epoch 131/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.1866 - acc: 0.9792 - val_loss: 0.1846 - val_acc: 0.9583\n",
            "Epoch 132/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.1872 - acc: 0.9792 - val_loss: 0.1836 - val_acc: 0.9583\n",
            "Epoch 133/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1837 - acc: 0.9792 - val_loss: 0.1781 - val_acc: 0.9583\n",
            "Epoch 134/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1854 - acc: 0.9688 - val_loss: 0.1747 - val_acc: 0.9583\n",
            "Epoch 135/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.1834 - acc: 0.9792 - val_loss: 0.1834 - val_acc: 0.9583\n",
            "Epoch 136/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.1809 - acc: 0.9792 - val_loss: 0.1794 - val_acc: 0.9583\n",
            "Epoch 137/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.1796 - acc: 0.9792 - val_loss: 0.1787 - val_acc: 0.9583\n",
            "Epoch 138/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.1782 - acc: 0.9792 - val_loss: 0.1770 - val_acc: 0.9583\n",
            "Epoch 139/200\n",
            "96/96 [==============================] - 0s 280us/step - loss: 0.1771 - acc: 0.9792 - val_loss: 0.1757 - val_acc: 0.9583\n",
            "Epoch 140/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.1768 - acc: 0.9792 - val_loss: 0.1724 - val_acc: 0.9583\n",
            "Epoch 141/200\n",
            "96/96 [==============================] - 0s 280us/step - loss: 0.1767 - acc: 0.9792 - val_loss: 0.1722 - val_acc: 0.9583\n",
            "Epoch 142/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.1744 - acc: 0.9688 - val_loss: 0.1680 - val_acc: 0.9583\n",
            "Epoch 143/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.1756 - acc: 0.9792 - val_loss: 0.1722 - val_acc: 0.9583\n",
            "Epoch 144/200\n",
            "96/96 [==============================] - 0s 324us/step - loss: 0.1715 - acc: 0.9792 - val_loss: 0.1694 - val_acc: 0.9583\n",
            "Epoch 145/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.1714 - acc: 0.9792 - val_loss: 0.1662 - val_acc: 0.9583\n",
            "Epoch 146/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.1708 - acc: 0.9792 - val_loss: 0.1684 - val_acc: 0.9583\n",
            "Epoch 147/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.1691 - acc: 0.9792 - val_loss: 0.1639 - val_acc: 0.9583\n",
            "Epoch 148/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.1682 - acc: 0.9792 - val_loss: 0.1645 - val_acc: 0.9583\n",
            "Epoch 149/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.1681 - acc: 0.9792 - val_loss: 0.1664 - val_acc: 0.9583\n",
            "Epoch 150/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1669 - acc: 0.9792 - val_loss: 0.1631 - val_acc: 0.9583\n",
            "Epoch 151/200\n",
            "96/96 [==============================] - 0s 272us/step - loss: 0.1652 - acc: 0.9792 - val_loss: 0.1618 - val_acc: 0.9583\n",
            "Epoch 152/200\n",
            "96/96 [==============================] - 0s 327us/step - loss: 0.1659 - acc: 0.9792 - val_loss: 0.1629 - val_acc: 0.9583\n",
            "Epoch 153/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.1643 - acc: 0.9792 - val_loss: 0.1622 - val_acc: 0.9583\n",
            "Epoch 154/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.1621 - acc: 0.9792 - val_loss: 0.1586 - val_acc: 0.9583\n",
            "Epoch 155/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.1617 - acc: 0.9792 - val_loss: 0.1557 - val_acc: 0.9583\n",
            "Epoch 156/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.1615 - acc: 0.9792 - val_loss: 0.1558 - val_acc: 0.9583\n",
            "Epoch 157/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.1605 - acc: 0.9792 - val_loss: 0.1550 - val_acc: 0.9583\n",
            "Epoch 158/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1603 - acc: 0.9688 - val_loss: 0.1532 - val_acc: 0.9583\n",
            "Epoch 159/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.1593 - acc: 0.9792 - val_loss: 0.1549 - val_acc: 0.9583\n",
            "Epoch 160/200\n",
            "96/96 [==============================] - 0s 287us/step - loss: 0.1577 - acc: 0.9792 - val_loss: 0.1554 - val_acc: 0.9583\n",
            "Epoch 161/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.1565 - acc: 0.9792 - val_loss: 0.1548 - val_acc: 0.9583\n",
            "Epoch 162/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.1560 - acc: 0.9792 - val_loss: 0.1551 - val_acc: 0.9583\n",
            "Epoch 163/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.1553 - acc: 0.9792 - val_loss: 0.1561 - val_acc: 0.9583\n",
            "Epoch 164/200\n",
            "96/96 [==============================] - 0s 269us/step - loss: 0.1564 - acc: 0.9792 - val_loss: 0.1559 - val_acc: 0.9583\n",
            "Epoch 165/200\n",
            "96/96 [==============================] - 0s 360us/step - loss: 0.1530 - acc: 0.9792 - val_loss: 0.1495 - val_acc: 0.9583\n",
            "Epoch 166/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.1534 - acc: 0.9792 - val_loss: 0.1500 - val_acc: 0.9583\n",
            "Epoch 167/200\n",
            "96/96 [==============================] - 0s 306us/step - loss: 0.1515 - acc: 0.9792 - val_loss: 0.1499 - val_acc: 0.9583\n",
            "Epoch 168/200\n",
            "96/96 [==============================] - 0s 272us/step - loss: 0.1516 - acc: 0.9792 - val_loss: 0.1499 - val_acc: 0.9583\n",
            "Epoch 169/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.1510 - acc: 0.9792 - val_loss: 0.1463 - val_acc: 0.9583\n",
            "Epoch 170/200\n",
            "96/96 [==============================] - 0s 269us/step - loss: 0.1502 - acc: 0.9792 - val_loss: 0.1463 - val_acc: 0.9583\n",
            "Epoch 171/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.1497 - acc: 0.9688 - val_loss: 0.1433 - val_acc: 0.9583\n",
            "Epoch 172/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.1493 - acc: 0.9688 - val_loss: 0.1418 - val_acc: 0.9583\n",
            "Epoch 173/200\n",
            "96/96 [==============================] - 0s 278us/step - loss: 0.1481 - acc: 0.9792 - val_loss: 0.1425 - val_acc: 0.9583\n",
            "Epoch 174/200\n",
            "96/96 [==============================] - 0s 277us/step - loss: 0.1461 - acc: 0.9792 - val_loss: 0.1455 - val_acc: 0.9583\n",
            "Epoch 175/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.1459 - acc: 0.9792 - val_loss: 0.1482 - val_acc: 0.9583\n",
            "Epoch 176/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.1461 - acc: 0.9792 - val_loss: 0.1447 - val_acc: 0.9583\n",
            "Epoch 177/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.1452 - acc: 0.9792 - val_loss: 0.1430 - val_acc: 0.9583\n",
            "Epoch 178/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.1441 - acc: 0.9792 - val_loss: 0.1403 - val_acc: 0.9583\n",
            "Epoch 179/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.1462 - acc: 0.9688 - val_loss: 0.1371 - val_acc: 0.9583\n",
            "Epoch 180/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.1428 - acc: 0.9792 - val_loss: 0.1434 - val_acc: 0.9583\n",
            "Epoch 181/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.1422 - acc: 0.9792 - val_loss: 0.1395 - val_acc: 0.9583\n",
            "Epoch 182/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.1426 - acc: 0.9792 - val_loss: 0.1378 - val_acc: 0.9583\n",
            "Epoch 183/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.1412 - acc: 0.9792 - val_loss: 0.1381 - val_acc: 0.9583\n",
            "Epoch 184/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.1405 - acc: 0.9792 - val_loss: 0.1424 - val_acc: 0.9583\n",
            "Epoch 185/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.1423 - acc: 0.9792 - val_loss: 0.1366 - val_acc: 0.9583\n",
            "Epoch 186/200\n",
            "96/96 [==============================] - 0s 277us/step - loss: 0.1393 - acc: 0.9792 - val_loss: 0.1399 - val_acc: 0.9583\n",
            "Epoch 187/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.1384 - acc: 0.9792 - val_loss: 0.1356 - val_acc: 0.9583\n",
            "Epoch 188/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1381 - acc: 0.9792 - val_loss: 0.1348 - val_acc: 0.9583\n",
            "Epoch 189/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1376 - acc: 0.9792 - val_loss: 0.1359 - val_acc: 0.9583\n",
            "Epoch 190/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1366 - acc: 0.9792 - val_loss: 0.1344 - val_acc: 0.9583\n",
            "Epoch 191/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.1364 - acc: 0.9792 - val_loss: 0.1326 - val_acc: 0.9583\n",
            "Epoch 192/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.1351 - acc: 0.9792 - val_loss: 0.1314 - val_acc: 0.9583\n",
            "Epoch 193/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1352 - acc: 0.9792 - val_loss: 0.1305 - val_acc: 0.9583\n",
            "Epoch 194/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.1366 - acc: 0.9688 - val_loss: 0.1294 - val_acc: 0.9583\n",
            "Epoch 195/200\n",
            "96/96 [==============================] - 0s 273us/step - loss: 0.1344 - acc: 0.9792 - val_loss: 0.1311 - val_acc: 0.9583\n",
            "Epoch 196/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.1339 - acc: 0.9792 - val_loss: 0.1323 - val_acc: 0.9583\n",
            "Epoch 197/200\n",
            "96/96 [==============================] - 0s 328us/step - loss: 0.1343 - acc: 0.9792 - val_loss: 0.1306 - val_acc: 0.9583\n",
            "Epoch 198/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.1328 - acc: 0.9792 - val_loss: 0.1274 - val_acc: 0.9583\n",
            "Epoch 199/200\n",
            "96/96 [==============================] - 0s 277us/step - loss: 0.1315 - acc: 0.9792 - val_loss: 0.1274 - val_acc: 0.9583\n",
            "Epoch 200/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.1322 - acc: 0.9792 - val_loss: 0.1253 - val_acc: 0.9583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwYPK696zTqu",
        "colab_type": "code",
        "outputId": "9a8b35b4-f91f-4bed-886f-0bfc7851dbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "def plot_acc_loss(history):\n",
        "    f, (ax1, ax2) = plt.subplots(2,1, figsize=(10,10))\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax1.plot(history.history['loss'])\n",
        "    ax1.plot(history.history['val_loss'])\n",
        "    ax1.set_title('model loss')\n",
        "    ax1.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax2.plot(history.history['acc'])\n",
        "    ax2.plot(history.history['val_acc'])\n",
        "    ax2.set_title('model accuracy')\n",
        "    ax2.set_xlabel('epoch')\n",
        "    ax2.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.show()\n",
        "    \n",
        "plot_acc_loss(history)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJcCAYAAAA7Pup5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWYcv3Y71AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0yLK7eP_cN6",
        "colab_type": "text"
      },
      "source": [
        "## Examining the plot\n",
        "\n",
        "In this model loss plot we can see that the model's loss gradually drops at it reaches 200 epochs and that our training and validation data loss do not deviate from each other meaning there is no overfitting present.\n",
        "\n",
        "We can also see that the accuracy of the training and validation data sets increase in accuracy in a similar fashion meaning which also indicate that there is no significant overfitting in our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw2wWtw5zTqy",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model\n",
        "Now that we have trained our model, we can evaluate it's predictive performance on our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQtZLcOdzTq0",
        "colab_type": "code",
        "outputId": "46fa1441-068a-4f8c-e0a9-741cd88207ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"\\n\\n{0}: {1:.2f}%\".format(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 0s 62us/step\n",
            "\n",
            "\n",
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2ihtRTBQ9R",
        "colab_type": "text"
      },
      "source": [
        "Our accuracy across our test set is 96.67% meaning that if we were to use this model on new data from the same Iris dataset, it would correctly classify the Iris species 96.67% of the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnnHSuWHBmIT",
        "colab_type": "text"
      },
      "source": [
        "### The Confusion Matrix\n",
        "\n",
        "A confusion matrix is useful for describing the performance of a classification model. Instead of seeing generalised accuracy, we're able to look how each individual classification performs. \n",
        "\n",
        "In this case we can see that a sample of Versicolor was incorrectly classified as Virginica which we could try to improve in the future by altering our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEnF0buSzTq4",
        "colab_type": "code",
        "outputId": "a72b04b6-b251-4d9e-b54e-c3221805b93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "def draw_confusion_matrix(true, pred, labels):\n",
        "  \"\"\"\n",
        "  Drawing confusion matrix\n",
        "  \"\"\"\n",
        "  \n",
        "  cm = metrics.confusion_matrix(true, pred, labels)\n",
        "  ax = plt.subplot()\n",
        "  sns.heatmap(cm, annot=True, ax=ax)\n",
        "  ax.set_xticklabels(['Setosa', 'Versicolor', 'Virginica']+labels)\n",
        "  ax.set_yticklabels(['Setosa', 'Versicolor', 'Virginica']+labels)\n",
        "  ax.set_xlabel(\"Predicted Classification\")\n",
        "  ax.set_ylabel(\"True Classification\")\n",
        "  plt.show()\n",
        "  \n",
        "  return cm\n",
        "\n",
        "y_pred = model.predict_classes(X_test)\n",
        "y_test_encoded = [np.argmax(i) for i in y_test] # Reverse one hot encoded to label encoded\n",
        "matrix = draw_confusion_matrix(y_test_encoded, y_pred, [0,1,2]) #[setosa,versicolor, virginica]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNjMrKFfQZmYF5QrazKyg/j87nLaA4JTYlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhOFX6LUzTrD",
        "colab_type": "code",
        "outputId": "aa1b8f57-e8b7-4e98-de34-27878ad918c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"acc: {0:.2f}%\".format(np.sum(np.diag(matrix))*100/np.sum(matrix)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHe0CcqcsO1Q",
        "colab_type": "text"
      },
      "source": [
        "# Key Points\n",
        "\n",
        "\n",
        "*   Created a neural network to solve multiclass classification problem\n",
        "*   \"One hot encoded\" to categorise string target variable\n",
        "*  Different loss functions for different classfication problems\n",
        "* Confusion matrix and model improvements\n",
        "\n",
        "\n"
      ]
    }
  ]
}