{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 2 - multi-class iris.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UoA-eResearch/deep-learning-tutorial-2019/blob/master/Exercise%202%20-%20multi-class%20iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPQTvjnTzTqM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2: The Iris Dataset\n",
        "In this exercise we will create a neural network to classify 3 different types of Iris (Setosa, Versicolor and Virginica) based on their sepal length, sepal width, petal length and petal width.\n",
        "\n",
        "![Irises](http://dataaspirant.com/wp-content/uploads/2017/01/irises.png)\n",
        "\n",
        "This is a multi class classification problem. It is similar to the Pima Indian's binary classification exercise, but with three classes to predict instead of two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9VrMNin1Yi",
        "colab_type": "text"
      },
      "source": [
        "### Q: How many steps are there in creating a neural network model? Please list those steps\n",
        "\n",
        "*answer...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B9pUqCzTqO",
        "colab_type": "text"
      },
      "source": [
        "### Import dependencies\n",
        "Start by importing the dependencies we will need for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB8CJHppzTqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxNqXnJTzTqY",
        "colab_type": "text"
      },
      "source": [
        "### Import data\n",
        "The Iris dataset contains four features from 150 different Iris flowers. The features in the dataset are described below.\n",
        "\n",
        "* Sepal length (cm)\n",
        "* Sepal width (cm)\n",
        "* Petal length (cm)\n",
        "* Petal width (cm)\n",
        "* Class: Iris setosa, Iris versicolor or Iris virginica\n",
        "\n",
        "Sepals are the part of a flower that protect and support the petals. The petals surround the reproductive parts of the flower.\n",
        "\n",
        "![Iris labeled](http://terpconnect.umd.edu/~petersd/666/html/iris_with_labels.jpg)\n",
        "\n",
        "A snapshot of the dataset is illustrated below (not in order).\n",
        "\n",
        "|Sepal Length|Sepal Width|Petal Length|Petal Width|Class|\n",
        "|---|---|---|---|-----------|\n",
        "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
        "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
        "|7.0|3.2|4.7|1.4|Iris-versicolor|\n",
        "|6.4|3.2|4.5|1.5|Iris-versicolor|\n",
        "|6.3|3.3|6.0|2.5|Iris-virginica|\n",
        "|5.8|2.7|5.1|1.9|Iris-virginica|\n",
        "\n",
        "To load this data into memory, use the `np.loadtxt` function. The data type (`dtype`) is set to `str` because our input data is a mix of numbers and strings. This will be dealt with when we split the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wYz6SEDzTqY",
        "colab_type": "code",
        "outputId": "cb940845-d05e-4bdf-f9cb-1a69d516b4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data = np.loadtxt('https://raw.githubusercontent.com/UoA-eResearch/deep-learning-tutorial-2019/master/data/iris.csv', delimiter=\",\", dtype=str)\n",
        "print(data[:6]) #Show the first 6 rows"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['5.1' '3.5' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.9' '3.0' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.7' '3.2' '1.3' '0.2' 'Iris-setosa']\n",
            " ['4.6' '3.1' '1.5' '0.2' 'Iris-setosa']\n",
            " ['5.0' '3.6' '1.4' '0.2' 'Iris-setosa']\n",
            " ['5.4' '3.9' '1.7' '0.4' 'Iris-setosa']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGLO13AQzTqb",
        "colab_type": "text"
      },
      "source": [
        "Separate the data into input (X) and output (y) variables.\n",
        "\n",
        "Note that we convert the input data into floats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-EcR4awzTqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[:, 0:4].astype(float)\n",
        "y = data[:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zYDMAbzTqd",
        "colab_type": "text"
      },
      "source": [
        "If you look carefully at the target values, you will notice that they are strings, i.e. 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'.\n",
        "\n",
        "**Keras needs numbers or matrices to work with, so we will need to reformat the target values.**\n",
        "\n",
        "The problem with converting the class values to numbers (e.g. 'Iris-setosa' becomes 0, 'Iris-versicolor' 1 etc) is that it implies that the target values are ordinal. That is, 'Iris-setosa' is somehow less than 'Iris-versicolor', which is not the case for this dataset.\n",
        "\n",
        "A better way to represent classes in a multi-class classification problem, is to 'one hot encode' the target values. An example is shown below. A matrix of zeros is generated. Each row corresponds to a sample and each column corresponds to a particular class. A 1 is placed into the column to incidicate the class that it belongs too.\n",
        "\n",
        "|Iris-setosa|Iris-versicolor|Iris-virginica|\n",
        "|---|---|---|\n",
        "|1|0|0|\n",
        "|0|1|0|\n",
        "|0|0|1|\n",
        "\n",
        "One hot encoding is a two step process. First encode the target values (y) into an array of numbers using the `LabelEncoder` from scikit-learn and then one hot encode the numbers with the `np_utils.to_categorical` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmReXRywzTqe",
        "colab_type": "code",
        "outputId": "b42ee057-40d9-4b87-9beb-d66456eda82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_encoded = LabelEncoder().fit(y).transform(y) # Convert the classes into numbers\n",
        "y_encoded[45:55]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQgfvZcfzTqi",
        "colab_type": "code",
        "outputId": "9cfbab03-d044-41b9-d40e-637305af1c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_one_hot_encoded = np_utils.to_categorical(y_encoded) # One hot encode the numbers\n",
        "y_one_hot_encoded[45:55]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMbd6-LV9Rm_",
        "colab_type": "text"
      },
      "source": [
        "### Set seed\n",
        "Set a seed value so that when we repeatedly run our code we will get the same result. Using the same seed is important when you want to compare algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvjmpbYM9UN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9s47Jx9zTqk",
        "colab_type": "text"
      },
      "source": [
        "Like the previous exercise, use the `train_test_split` function from scikit-learn to split the input and target data into training, validation and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qdeRm6LzTql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f45724c-e1ed-489b-ff8d-763ad2cc8942"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_encoded, test_size=0.2, random_state=seed)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.9 3.  5.1 1.8]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.  2.2 5.  1.5]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [6.6 2.9 4.6 1.3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gp1FcnQzTqn",
        "colab_type": "text"
      },
      "source": [
        "### Create the model\n",
        "The code snippet below creates a very basic neural network model, with three layers: an input layer, a hidden layer and an output layer.\n",
        "\n",
        "The first layer is a fully connected `Dense` layer. We use four neurons in the hidden layer and have 4 input neurons for the 4 features.\n",
        "\n",
        "The last layer has 3 neurons, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG9oXx6dzTqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McwgpeyfzTqp",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "We then compile the model. The loss function is set to `categorical_crossentropy` (different from the loss function used in the binary classification exercise) because we are performing multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F86R20yJzTqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr-3q6CEzTqs",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "Now that we have compiled the model, we can train it with the data we prepared earlier. We are using more epochs but a smaller batch size than the previous exercise.\n",
        "\n",
        "To see the model training history in text, just don't include `verbose=0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ohIS-DzTqs",
        "colab_type": "code",
        "outputId": "abc9673a-5a9c-4fc2-9aa8-1ea128e9d2c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=5)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 96 samples, validate on 24 samples\n",
            "Epoch 1/200\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 1.0998 - acc: 0.3438 - val_loss: 1.0979 - val_acc: 0.4167\n",
            "Epoch 2/200\n",
            "96/96 [==============================] - 0s 267us/step - loss: 1.0972 - acc: 0.5833 - val_loss: 1.0968 - val_acc: 0.6667\n",
            "Epoch 3/200\n",
            "96/96 [==============================] - 0s 274us/step - loss: 1.0953 - acc: 0.6458 - val_loss: 1.0951 - val_acc: 0.6250\n",
            "Epoch 4/200\n",
            "96/96 [==============================] - 0s 258us/step - loss: 1.0927 - acc: 0.3854 - val_loss: 1.0932 - val_acc: 0.2500\n",
            "Epoch 5/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 1.0887 - acc: 0.3438 - val_loss: 1.0900 - val_acc: 0.2500\n",
            "Epoch 6/200\n",
            "96/96 [==============================] - 0s 313us/step - loss: 1.0836 - acc: 0.3438 - val_loss: 1.0856 - val_acc: 0.2500\n",
            "Epoch 7/200\n",
            "96/96 [==============================] - 0s 259us/step - loss: 1.0771 - acc: 0.3854 - val_loss: 1.0793 - val_acc: 0.3750\n",
            "Epoch 8/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 1.0690 - acc: 0.5625 - val_loss: 1.0708 - val_acc: 0.6250\n",
            "Epoch 9/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 1.0587 - acc: 0.6458 - val_loss: 1.0613 - val_acc: 0.6667\n",
            "Epoch 10/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 1.0471 - acc: 0.6563 - val_loss: 1.0500 - val_acc: 0.6667\n",
            "Epoch 11/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 1.0337 - acc: 0.6875 - val_loss: 1.0357 - val_acc: 0.6667\n",
            "Epoch 12/200\n",
            "96/96 [==============================] - 0s 422us/step - loss: 1.0181 - acc: 0.6875 - val_loss: 1.0203 - val_acc: 0.6667\n",
            "Epoch 13/200\n",
            "96/96 [==============================] - 0s 264us/step - loss: 1.0002 - acc: 0.6875 - val_loss: 1.0004 - val_acc: 0.6667\n",
            "Epoch 14/200\n",
            "96/96 [==============================] - 0s 322us/step - loss: 0.9806 - acc: 0.6875 - val_loss: 0.9816 - val_acc: 0.6667\n",
            "Epoch 15/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.9590 - acc: 0.6875 - val_loss: 0.9600 - val_acc: 0.6667\n",
            "Epoch 16/200\n",
            "96/96 [==============================] - 0s 315us/step - loss: 0.9379 - acc: 0.6875 - val_loss: 0.9369 - val_acc: 0.6667\n",
            "Epoch 17/200\n",
            "96/96 [==============================] - 0s 356us/step - loss: 0.9172 - acc: 0.6875 - val_loss: 0.9173 - val_acc: 0.6667\n",
            "Epoch 18/200\n",
            "96/96 [==============================] - 0s 352us/step - loss: 0.8928 - acc: 0.6875 - val_loss: 0.8920 - val_acc: 0.6667\n",
            "Epoch 19/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.8704 - acc: 0.6875 - val_loss: 0.8681 - val_acc: 0.6667\n",
            "Epoch 20/200\n",
            "96/96 [==============================] - 0s 364us/step - loss: 0.8476 - acc: 0.6875 - val_loss: 0.8432 - val_acc: 0.6667\n",
            "Epoch 21/200\n",
            "96/96 [==============================] - 0s 303us/step - loss: 0.8254 - acc: 0.6875 - val_loss: 0.8196 - val_acc: 0.6667\n",
            "Epoch 22/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.8029 - acc: 0.6875 - val_loss: 0.7986 - val_acc: 0.6667\n",
            "Epoch 23/200\n",
            "96/96 [==============================] - 0s 325us/step - loss: 0.7817 - acc: 0.6875 - val_loss: 0.7746 - val_acc: 0.6667\n",
            "Epoch 24/200\n",
            "96/96 [==============================] - 0s 287us/step - loss: 0.7594 - acc: 0.6875 - val_loss: 0.7508 - val_acc: 0.6667\n",
            "Epoch 25/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.7383 - acc: 0.6875 - val_loss: 0.7298 - val_acc: 0.6667\n",
            "Epoch 26/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.7187 - acc: 0.6875 - val_loss: 0.7066 - val_acc: 0.6667\n",
            "Epoch 27/200\n",
            "96/96 [==============================] - 0s 341us/step - loss: 0.6994 - acc: 0.6875 - val_loss: 0.6899 - val_acc: 0.6667\n",
            "Epoch 28/200\n",
            "96/96 [==============================] - 0s 328us/step - loss: 0.6798 - acc: 0.6875 - val_loss: 0.6671 - val_acc: 0.6667\n",
            "Epoch 29/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.6624 - acc: 0.6875 - val_loss: 0.6503 - val_acc: 0.6667\n",
            "Epoch 30/200\n",
            "96/96 [==============================] - 0s 298us/step - loss: 0.6441 - acc: 0.6875 - val_loss: 0.6307 - val_acc: 0.6667\n",
            "Epoch 31/200\n",
            "96/96 [==============================] - 0s 280us/step - loss: 0.6287 - acc: 0.6875 - val_loss: 0.6149 - val_acc: 0.7083\n",
            "Epoch 32/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.6133 - acc: 0.6875 - val_loss: 0.5960 - val_acc: 0.7083\n",
            "Epoch 33/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.5978 - acc: 0.7083 - val_loss: 0.5809 - val_acc: 0.7083\n",
            "Epoch 34/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.5834 - acc: 0.7083 - val_loss: 0.5660 - val_acc: 0.7083\n",
            "Epoch 35/200\n",
            "96/96 [==============================] - 0s 302us/step - loss: 0.5692 - acc: 0.7292 - val_loss: 0.5492 - val_acc: 0.7083\n",
            "Epoch 36/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.5558 - acc: 0.8125 - val_loss: 0.5341 - val_acc: 0.7917\n",
            "Epoch 37/200\n",
            "96/96 [==============================] - 0s 298us/step - loss: 0.5434 - acc: 0.7708 - val_loss: 0.5246 - val_acc: 0.7083\n",
            "Epoch 38/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.5312 - acc: 0.8333 - val_loss: 0.5095 - val_acc: 0.8333\n",
            "Epoch 39/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.5195 - acc: 0.8542 - val_loss: 0.4988 - val_acc: 0.8333\n",
            "Epoch 40/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.5085 - acc: 0.8854 - val_loss: 0.4848 - val_acc: 0.9167\n",
            "Epoch 41/200\n",
            "96/96 [==============================] - 0s 277us/step - loss: 0.4972 - acc: 0.9167 - val_loss: 0.4750 - val_acc: 0.9167\n",
            "Epoch 42/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.4890 - acc: 0.8750 - val_loss: 0.4669 - val_acc: 0.8333\n",
            "Epoch 43/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.4780 - acc: 0.8750 - val_loss: 0.4578 - val_acc: 0.8333\n",
            "Epoch 44/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.4679 - acc: 0.8958 - val_loss: 0.4467 - val_acc: 0.9167\n",
            "Epoch 45/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.4588 - acc: 0.9271 - val_loss: 0.4373 - val_acc: 0.9167\n",
            "Epoch 46/200\n",
            "96/96 [==============================] - 0s 370us/step - loss: 0.4500 - acc: 0.9688 - val_loss: 0.4286 - val_acc: 0.9167\n",
            "Epoch 47/200\n",
            "96/96 [==============================] - 0s 308us/step - loss: 0.4415 - acc: 0.9375 - val_loss: 0.4215 - val_acc: 0.9167\n",
            "Epoch 48/200\n",
            "96/96 [==============================] - 0s 363us/step - loss: 0.4338 - acc: 0.9167 - val_loss: 0.4137 - val_acc: 0.9167\n",
            "Epoch 49/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.4269 - acc: 0.8958 - val_loss: 0.4085 - val_acc: 0.9167\n",
            "Epoch 50/200\n",
            "96/96 [==============================] - 0s 346us/step - loss: 0.4175 - acc: 0.9271 - val_loss: 0.3980 - val_acc: 0.9583\n",
            "Epoch 51/200\n",
            "96/96 [==============================] - 0s 312us/step - loss: 0.4102 - acc: 0.9792 - val_loss: 0.3902 - val_acc: 0.9583\n",
            "Epoch 52/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.4036 - acc: 0.9792 - val_loss: 0.3846 - val_acc: 0.9583\n",
            "Epoch 53/200\n",
            "96/96 [==============================] - 0s 277us/step - loss: 0.3991 - acc: 0.9792 - val_loss: 0.3753 - val_acc: 0.9583\n",
            "Epoch 54/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.3895 - acc: 0.9792 - val_loss: 0.3736 - val_acc: 0.9583\n",
            "Epoch 55/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.3842 - acc: 0.9583 - val_loss: 0.3689 - val_acc: 0.9583\n",
            "Epoch 56/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.3796 - acc: 0.9792 - val_loss: 0.3585 - val_acc: 0.9583\n",
            "Epoch 57/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.3716 - acc: 0.9792 - val_loss: 0.3578 - val_acc: 0.9583\n",
            "Epoch 58/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.3662 - acc: 0.9792 - val_loss: 0.3508 - val_acc: 0.9583\n",
            "Epoch 59/200\n",
            "96/96 [==============================] - 0s 380us/step - loss: 0.3609 - acc: 0.9792 - val_loss: 0.3443 - val_acc: 0.9583\n",
            "Epoch 60/200\n",
            "96/96 [==============================] - 0s 311us/step - loss: 0.3559 - acc: 0.9792 - val_loss: 0.3436 - val_acc: 0.9583\n",
            "Epoch 61/200\n",
            "96/96 [==============================] - 0s 298us/step - loss: 0.3517 - acc: 0.9792 - val_loss: 0.3347 - val_acc: 0.9583\n",
            "Epoch 62/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.3473 - acc: 0.9792 - val_loss: 0.3308 - val_acc: 0.9583\n",
            "Epoch 63/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.3414 - acc: 0.9792 - val_loss: 0.3263 - val_acc: 0.9583\n",
            "Epoch 64/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.3386 - acc: 0.9792 - val_loss: 0.3221 - val_acc: 0.9583\n",
            "Epoch 65/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.3323 - acc: 0.9792 - val_loss: 0.3198 - val_acc: 0.9583\n",
            "Epoch 66/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.3287 - acc: 0.9792 - val_loss: 0.3189 - val_acc: 0.9583\n",
            "Epoch 67/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.3238 - acc: 0.9792 - val_loss: 0.3097 - val_acc: 0.9583\n",
            "Epoch 68/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.3220 - acc: 0.9792 - val_loss: 0.3092 - val_acc: 0.9583\n",
            "Epoch 69/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.3164 - acc: 0.9792 - val_loss: 0.3046 - val_acc: 0.9583\n",
            "Epoch 70/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.3151 - acc: 0.9792 - val_loss: 0.3040 - val_acc: 0.9583\n",
            "Epoch 71/200\n",
            "96/96 [==============================] - 0s 274us/step - loss: 0.3087 - acc: 0.9792 - val_loss: 0.2959 - val_acc: 0.9583\n",
            "Epoch 72/200\n",
            "96/96 [==============================] - 0s 265us/step - loss: 0.3068 - acc: 0.9792 - val_loss: 0.2922 - val_acc: 0.9583\n",
            "Epoch 73/200\n",
            "96/96 [==============================] - 0s 272us/step - loss: 0.3026 - acc: 0.9792 - val_loss: 0.2911 - val_acc: 0.9583\n",
            "Epoch 74/200\n",
            "96/96 [==============================] - 0s 320us/step - loss: 0.3035 - acc: 0.9792 - val_loss: 0.2944 - val_acc: 0.9583\n",
            "Epoch 75/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.2963 - acc: 0.9792 - val_loss: 0.2861 - val_acc: 0.9583\n",
            "Epoch 76/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.2922 - acc: 0.9792 - val_loss: 0.2856 - val_acc: 0.9583\n",
            "Epoch 77/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.2896 - acc: 0.9792 - val_loss: 0.2843 - val_acc: 0.9583\n",
            "Epoch 78/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.2878 - acc: 0.9792 - val_loss: 0.2818 - val_acc: 0.9583\n",
            "Epoch 79/200\n",
            "96/96 [==============================] - 0s 298us/step - loss: 0.2834 - acc: 0.9792 - val_loss: 0.2744 - val_acc: 0.9583\n",
            "Epoch 80/200\n",
            "96/96 [==============================] - 0s 336us/step - loss: 0.2814 - acc: 0.9792 - val_loss: 0.2717 - val_acc: 0.9583\n",
            "Epoch 81/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.2781 - acc: 0.9792 - val_loss: 0.2699 - val_acc: 0.9583\n",
            "Epoch 82/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.2766 - acc: 0.9792 - val_loss: 0.2710 - val_acc: 0.9583\n",
            "Epoch 83/200\n",
            "96/96 [==============================] - 0s 309us/step - loss: 0.2733 - acc: 0.9792 - val_loss: 0.2669 - val_acc: 0.9583\n",
            "Epoch 84/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.2718 - acc: 0.9792 - val_loss: 0.2667 - val_acc: 0.9583\n",
            "Epoch 85/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.2678 - acc: 0.9792 - val_loss: 0.2592 - val_acc: 0.9583\n",
            "Epoch 86/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.2659 - acc: 0.9792 - val_loss: 0.2546 - val_acc: 0.9583\n",
            "Epoch 87/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.2657 - acc: 0.9792 - val_loss: 0.2562 - val_acc: 0.9583\n",
            "Epoch 88/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.2638 - acc: 0.9792 - val_loss: 0.2508 - val_acc: 0.9583\n",
            "Epoch 89/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.2588 - acc: 0.9792 - val_loss: 0.2530 - val_acc: 0.9583\n",
            "Epoch 90/200\n",
            "96/96 [==============================] - 0s 333us/step - loss: 0.2559 - acc: 0.9792 - val_loss: 0.2479 - val_acc: 0.9583\n",
            "Epoch 91/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.2537 - acc: 0.9792 - val_loss: 0.2496 - val_acc: 0.9583\n",
            "Epoch 92/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.2514 - acc: 0.9792 - val_loss: 0.2486 - val_acc: 0.9583\n",
            "Epoch 93/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.2509 - acc: 0.9792 - val_loss: 0.2479 - val_acc: 0.9583\n",
            "Epoch 94/200\n",
            "96/96 [==============================] - 0s 278us/step - loss: 0.2470 - acc: 0.9792 - val_loss: 0.2396 - val_acc: 0.9583\n",
            "Epoch 95/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.2443 - acc: 0.9792 - val_loss: 0.2382 - val_acc: 0.9583\n",
            "Epoch 96/200\n",
            "96/96 [==============================] - 0s 295us/step - loss: 0.2444 - acc: 0.9792 - val_loss: 0.2394 - val_acc: 0.9583\n",
            "Epoch 97/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.2408 - acc: 0.9792 - val_loss: 0.2353 - val_acc: 0.9583\n",
            "Epoch 98/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.2387 - acc: 0.9792 - val_loss: 0.2307 - val_acc: 0.9583\n",
            "Epoch 99/200\n",
            "96/96 [==============================] - 0s 276us/step - loss: 0.2360 - acc: 0.9792 - val_loss: 0.2305 - val_acc: 0.9583\n",
            "Epoch 100/200\n",
            "96/96 [==============================] - 0s 298us/step - loss: 0.2357 - acc: 0.9792 - val_loss: 0.2322 - val_acc: 0.9583\n",
            "Epoch 101/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.2333 - acc: 0.9792 - val_loss: 0.2283 - val_acc: 0.9583\n",
            "Epoch 102/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.2302 - acc: 0.9792 - val_loss: 0.2258 - val_acc: 0.9583\n",
            "Epoch 103/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.2330 - acc: 0.9688 - val_loss: 0.2200 - val_acc: 0.9583\n",
            "Epoch 104/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.2279 - acc: 0.9792 - val_loss: 0.2235 - val_acc: 0.9583\n",
            "Epoch 105/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.2254 - acc: 0.9792 - val_loss: 0.2197 - val_acc: 0.9583\n",
            "Epoch 106/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.2228 - acc: 0.9792 - val_loss: 0.2191 - val_acc: 0.9583\n",
            "Epoch 107/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.2230 - acc: 0.9792 - val_loss: 0.2206 - val_acc: 0.9583\n",
            "Epoch 108/200\n",
            "96/96 [==============================] - 0s 266us/step - loss: 0.2211 - acc: 0.9792 - val_loss: 0.2180 - val_acc: 0.9583\n",
            "Epoch 109/200\n",
            "96/96 [==============================] - 0s 359us/step - loss: 0.2191 - acc: 0.9792 - val_loss: 0.2144 - val_acc: 0.9583\n",
            "Epoch 110/200\n",
            "96/96 [==============================] - 0s 310us/step - loss: 0.2167 - acc: 0.9792 - val_loss: 0.2123 - val_acc: 0.9583\n",
            "Epoch 111/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.2150 - acc: 0.9792 - val_loss: 0.2088 - val_acc: 0.9583\n",
            "Epoch 112/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.2151 - acc: 0.9792 - val_loss: 0.2105 - val_acc: 0.9583\n",
            "Epoch 113/200\n",
            "96/96 [==============================] - 0s 269us/step - loss: 0.2124 - acc: 0.9792 - val_loss: 0.2077 - val_acc: 0.9583\n",
            "Epoch 114/200\n",
            "96/96 [==============================] - 0s 280us/step - loss: 0.2102 - acc: 0.9792 - val_loss: 0.2062 - val_acc: 0.9583\n",
            "Epoch 115/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.2095 - acc: 0.9792 - val_loss: 0.2070 - val_acc: 0.9583\n",
            "Epoch 116/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.2057 - acc: 0.9792 - val_loss: 0.1996 - val_acc: 0.9583\n",
            "Epoch 117/200\n",
            "96/96 [==============================] - 0s 325us/step - loss: 0.2056 - acc: 0.9792 - val_loss: 0.2000 - val_acc: 0.9583\n",
            "Epoch 118/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.2038 - acc: 0.9792 - val_loss: 0.1981 - val_acc: 0.9583\n",
            "Epoch 119/200\n",
            "96/96 [==============================] - 0s 281us/step - loss: 0.2024 - acc: 0.9792 - val_loss: 0.2017 - val_acc: 0.9583\n",
            "Epoch 120/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.2019 - acc: 0.9792 - val_loss: 0.1976 - val_acc: 0.9583\n",
            "Epoch 121/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.1991 - acc: 0.9792 - val_loss: 0.1994 - val_acc: 0.9583\n",
            "Epoch 122/200\n",
            "96/96 [==============================] - 0s 283us/step - loss: 0.1987 - acc: 0.9792 - val_loss: 0.1962 - val_acc: 0.9583\n",
            "Epoch 123/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1967 - acc: 0.9792 - val_loss: 0.1949 - val_acc: 0.9583\n",
            "Epoch 124/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.1972 - acc: 0.9792 - val_loss: 0.1998 - val_acc: 0.9583\n",
            "Epoch 125/200\n",
            "96/96 [==============================] - 0s 271us/step - loss: 0.1950 - acc: 0.9792 - val_loss: 0.1946 - val_acc: 0.9583\n",
            "Epoch 126/200\n",
            "96/96 [==============================] - 0s 325us/step - loss: 0.1953 - acc: 0.9792 - val_loss: 0.1844 - val_acc: 0.9583\n",
            "Epoch 127/200\n",
            "96/96 [==============================] - 0s 352us/step - loss: 0.1939 - acc: 0.9688 - val_loss: 0.1897 - val_acc: 0.9583\n",
            "Epoch 128/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.1904 - acc: 0.9792 - val_loss: 0.1834 - val_acc: 0.9583\n",
            "Epoch 129/200\n",
            "96/96 [==============================] - 0s 306us/step - loss: 0.1893 - acc: 0.9688 - val_loss: 0.1843 - val_acc: 0.9583\n",
            "Epoch 130/200\n",
            "96/96 [==============================] - 0s 274us/step - loss: 0.1888 - acc: 0.9792 - val_loss: 0.1834 - val_acc: 0.9583\n",
            "Epoch 131/200\n",
            "96/96 [==============================] - 0s 278us/step - loss: 0.1865 - acc: 0.9792 - val_loss: 0.1845 - val_acc: 0.9583\n",
            "Epoch 132/200\n",
            "96/96 [==============================] - 0s 282us/step - loss: 0.1871 - acc: 0.9792 - val_loss: 0.1835 - val_acc: 0.9583\n",
            "Epoch 133/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.1836 - acc: 0.9792 - val_loss: 0.1780 - val_acc: 0.9583\n",
            "Epoch 134/200\n",
            "96/96 [==============================] - 0s 316us/step - loss: 0.1853 - acc: 0.9688 - val_loss: 0.1746 - val_acc: 0.9583\n",
            "Epoch 135/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.1833 - acc: 0.9792 - val_loss: 0.1833 - val_acc: 0.9583\n",
            "Epoch 136/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.1808 - acc: 0.9792 - val_loss: 0.1793 - val_acc: 0.9583\n",
            "Epoch 137/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.1795 - acc: 0.9792 - val_loss: 0.1786 - val_acc: 0.9583\n",
            "Epoch 138/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.1781 - acc: 0.9792 - val_loss: 0.1769 - val_acc: 0.9583\n",
            "Epoch 139/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.1770 - acc: 0.9792 - val_loss: 0.1756 - val_acc: 0.9583\n",
            "Epoch 140/200\n",
            "96/96 [==============================] - 0s 329us/step - loss: 0.1766 - acc: 0.9792 - val_loss: 0.1723 - val_acc: 0.9583\n",
            "Epoch 141/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.1766 - acc: 0.9792 - val_loss: 0.1721 - val_acc: 0.9583\n",
            "Epoch 142/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.1743 - acc: 0.9688 - val_loss: 0.1679 - val_acc: 0.9583\n",
            "Epoch 143/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.1755 - acc: 0.9792 - val_loss: 0.1721 - val_acc: 0.9583\n",
            "Epoch 144/200\n",
            "96/96 [==============================] - 0s 264us/step - loss: 0.1714 - acc: 0.9792 - val_loss: 0.1693 - val_acc: 0.9583\n",
            "Epoch 145/200\n",
            "96/96 [==============================] - 0s 268us/step - loss: 0.1713 - acc: 0.9792 - val_loss: 0.1661 - val_acc: 0.9583\n",
            "Epoch 146/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.1707 - acc: 0.9792 - val_loss: 0.1683 - val_acc: 0.9583\n",
            "Epoch 147/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.1690 - acc: 0.9792 - val_loss: 0.1638 - val_acc: 0.9583\n",
            "Epoch 148/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.1681 - acc: 0.9792 - val_loss: 0.1644 - val_acc: 0.9583\n",
            "Epoch 149/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.1680 - acc: 0.9792 - val_loss: 0.1663 - val_acc: 0.9583\n",
            "Epoch 150/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.1668 - acc: 0.9792 - val_loss: 0.1630 - val_acc: 0.9583\n",
            "Epoch 151/200\n",
            "96/96 [==============================] - 0s 312us/step - loss: 0.1651 - acc: 0.9792 - val_loss: 0.1617 - val_acc: 0.9583\n",
            "Epoch 152/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.1658 - acc: 0.9792 - val_loss: 0.1628 - val_acc: 0.9583\n",
            "Epoch 153/200\n",
            "96/96 [==============================] - 0s 274us/step - loss: 0.1642 - acc: 0.9792 - val_loss: 0.1621 - val_acc: 0.9583\n",
            "Epoch 154/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1620 - acc: 0.9792 - val_loss: 0.1585 - val_acc: 0.9583\n",
            "Epoch 155/200\n",
            "96/96 [==============================] - 0s 301us/step - loss: 0.1616 - acc: 0.9792 - val_loss: 0.1556 - val_acc: 0.9583\n",
            "Epoch 156/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.1614 - acc: 0.9792 - val_loss: 0.1557 - val_acc: 0.9583\n",
            "Epoch 157/200\n",
            "96/96 [==============================] - 0s 290us/step - loss: 0.1604 - acc: 0.9792 - val_loss: 0.1549 - val_acc: 0.9583\n",
            "Epoch 158/200\n",
            "96/96 [==============================] - 0s 271us/step - loss: 0.1602 - acc: 0.9688 - val_loss: 0.1531 - val_acc: 0.9583\n",
            "Epoch 159/200\n",
            "96/96 [==============================] - 0s 275us/step - loss: 0.1592 - acc: 0.9792 - val_loss: 0.1548 - val_acc: 0.9583\n",
            "Epoch 160/200\n",
            "96/96 [==============================] - 0s 279us/step - loss: 0.1576 - acc: 0.9792 - val_loss: 0.1553 - val_acc: 0.9583\n",
            "Epoch 161/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.1564 - acc: 0.9792 - val_loss: 0.1547 - val_acc: 0.9583\n",
            "Epoch 162/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.1560 - acc: 0.9792 - val_loss: 0.1550 - val_acc: 0.9583\n",
            "Epoch 163/200\n",
            "96/96 [==============================] - 0s 271us/step - loss: 0.1552 - acc: 0.9792 - val_loss: 0.1560 - val_acc: 0.9583\n",
            "Epoch 164/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.1563 - acc: 0.9792 - val_loss: 0.1558 - val_acc: 0.9583\n",
            "Epoch 165/200\n",
            "96/96 [==============================] - 0s 265us/step - loss: 0.1529 - acc: 0.9792 - val_loss: 0.1494 - val_acc: 0.9583\n",
            "Epoch 166/200\n",
            "96/96 [==============================] - 0s 284us/step - loss: 0.1533 - acc: 0.9792 - val_loss: 0.1499 - val_acc: 0.9583\n",
            "Epoch 167/200\n",
            "96/96 [==============================] - 0s 307us/step - loss: 0.1515 - acc: 0.9792 - val_loss: 0.1499 - val_acc: 0.9583\n",
            "Epoch 168/200\n",
            "96/96 [==============================] - 0s 341us/step - loss: 0.1515 - acc: 0.9792 - val_loss: 0.1498 - val_acc: 0.9583\n",
            "Epoch 169/200\n",
            "96/96 [==============================] - 0s 308us/step - loss: 0.1509 - acc: 0.9792 - val_loss: 0.1462 - val_acc: 0.9583\n",
            "Epoch 170/200\n",
            "96/96 [==============================] - 0s 306us/step - loss: 0.1501 - acc: 0.9792 - val_loss: 0.1462 - val_acc: 0.9583\n",
            "Epoch 171/200\n",
            "96/96 [==============================] - 0s 329us/step - loss: 0.1496 - acc: 0.9688 - val_loss: 0.1432 - val_acc: 0.9583\n",
            "Epoch 172/200\n",
            "96/96 [==============================] - 0s 287us/step - loss: 0.1493 - acc: 0.9688 - val_loss: 0.1417 - val_acc: 0.9583\n",
            "Epoch 173/200\n",
            "96/96 [==============================] - 0s 293us/step - loss: 0.1480 - acc: 0.9792 - val_loss: 0.1424 - val_acc: 0.9583\n",
            "Epoch 174/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.1461 - acc: 0.9792 - val_loss: 0.1454 - val_acc: 0.9583\n",
            "Epoch 175/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.1458 - acc: 0.9792 - val_loss: 0.1481 - val_acc: 0.9583\n",
            "Epoch 176/200\n",
            "96/96 [==============================] - 0s 267us/step - loss: 0.1460 - acc: 0.9792 - val_loss: 0.1446 - val_acc: 0.9583\n",
            "Epoch 177/200\n",
            "96/96 [==============================] - 0s 363us/step - loss: 0.1451 - acc: 0.9792 - val_loss: 0.1429 - val_acc: 0.9583\n",
            "Epoch 178/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.1440 - acc: 0.9792 - val_loss: 0.1403 - val_acc: 0.9583\n",
            "Epoch 179/200\n",
            "96/96 [==============================] - 0s 291us/step - loss: 0.1461 - acc: 0.9688 - val_loss: 0.1371 - val_acc: 0.9583\n",
            "Epoch 180/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.1427 - acc: 0.9792 - val_loss: 0.1433 - val_acc: 0.9583\n",
            "Epoch 181/200\n",
            "96/96 [==============================] - 0s 305us/step - loss: 0.1421 - acc: 0.9792 - val_loss: 0.1394 - val_acc: 0.9583\n",
            "Epoch 182/200\n",
            "96/96 [==============================] - 0s 324us/step - loss: 0.1425 - acc: 0.9792 - val_loss: 0.1378 - val_acc: 0.9583\n",
            "Epoch 183/200\n",
            "96/96 [==============================] - 0s 294us/step - loss: 0.1411 - acc: 0.9792 - val_loss: 0.1380 - val_acc: 0.9583\n",
            "Epoch 184/200\n",
            "96/96 [==============================] - 0s 324us/step - loss: 0.1404 - acc: 0.9792 - val_loss: 0.1423 - val_acc: 0.9583\n",
            "Epoch 185/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.1422 - acc: 0.9792 - val_loss: 0.1365 - val_acc: 0.9583\n",
            "Epoch 186/200\n",
            "96/96 [==============================] - 0s 288us/step - loss: 0.1392 - acc: 0.9792 - val_loss: 0.1398 - val_acc: 0.9583\n",
            "Epoch 187/200\n",
            "96/96 [==============================] - 0s 306us/step - loss: 0.1384 - acc: 0.9792 - val_loss: 0.1355 - val_acc: 0.9583\n",
            "Epoch 188/200\n",
            "96/96 [==============================] - 0s 297us/step - loss: 0.1380 - acc: 0.9792 - val_loss: 0.1347 - val_acc: 0.9583\n",
            "Epoch 189/200\n",
            "96/96 [==============================] - 0s 337us/step - loss: 0.1375 - acc: 0.9792 - val_loss: 0.1358 - val_acc: 0.9583\n",
            "Epoch 190/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.1366 - acc: 0.9792 - val_loss: 0.1343 - val_acc: 0.9583\n",
            "Epoch 191/200\n",
            "96/96 [==============================] - 0s 289us/step - loss: 0.1364 - acc: 0.9792 - val_loss: 0.1325 - val_acc: 0.9583\n",
            "Epoch 192/200\n",
            "96/96 [==============================] - 0s 328us/step - loss: 0.1350 - acc: 0.9792 - val_loss: 0.1313 - val_acc: 0.9583\n",
            "Epoch 193/200\n",
            "96/96 [==============================] - 0s 285us/step - loss: 0.1351 - acc: 0.9792 - val_loss: 0.1304 - val_acc: 0.9583\n",
            "Epoch 194/200\n",
            "96/96 [==============================] - 0s 328us/step - loss: 0.1365 - acc: 0.9688 - val_loss: 0.1293 - val_acc: 0.9583\n",
            "Epoch 195/200\n",
            "96/96 [==============================] - 0s 292us/step - loss: 0.1343 - acc: 0.9792 - val_loss: 0.1310 - val_acc: 0.9583\n",
            "Epoch 196/200\n",
            "96/96 [==============================] - 0s 299us/step - loss: 0.1338 - acc: 0.9792 - val_loss: 0.1322 - val_acc: 0.9583\n",
            "Epoch 197/200\n",
            "96/96 [==============================] - 0s 296us/step - loss: 0.1343 - acc: 0.9792 - val_loss: 0.1306 - val_acc: 0.9583\n",
            "Epoch 198/200\n",
            "96/96 [==============================] - 0s 300us/step - loss: 0.1327 - acc: 0.9792 - val_loss: 0.1273 - val_acc: 0.9583\n",
            "Epoch 199/200\n",
            "96/96 [==============================] - 0s 286us/step - loss: 0.1315 - acc: 0.9792 - val_loss: 0.1273 - val_acc: 0.9583\n",
            "Epoch 200/200\n",
            "96/96 [==============================] - 0s 304us/step - loss: 0.1321 - acc: 0.9792 - val_loss: 0.1253 - val_acc: 0.9583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHreB--UHEuB",
        "colab_type": "text"
      },
      "source": [
        "### Examining the plot\n",
        "\n",
        "In this model loss plot we can see that the model's loss gradually drops at it reaches 200 epochs and that our training and validation data loss do not deviate from each other meaning there is no overfitting present.\n",
        "\n",
        "We can also see that the accuracy of the training and validation data sets increase in accuracy in a similar fashion meaning which also indicate that there is no significant overfitting in our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwYPK696zTqu",
        "colab_type": "code",
        "outputId": "24598f32-4ddf-4551-f512-6b876b963ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "def plot_acc_loss(history):\n",
        "    f, (ax1, ax2) = plt.subplots(2,1, figsize=(10,10))\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax1.plot(history.history['loss'])\n",
        "    ax1.plot(history.history['val_loss'])\n",
        "    ax1.set_title('model loss')\n",
        "    ax1.legend(['train', 'val'], loc='upper left')\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax2.plot(history.history['acc'])\n",
        "    ax2.plot(history.history['val_acc'])\n",
        "    ax2.set_title('model accuracy')\n",
        "    ax2.set_xlabel('epoch')\n",
        "    ax2.legend(['train', 'val'], loc='upper left')\n",
        "    \n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.show()\n",
        "    \n",
        "plot_acc_loss(history)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJcCAYAAAA7Pup5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw2wWtw5zTqy",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model\n",
        "Now that we have trained our model, we can evaluate it's predictive performance on our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQtZLcOdzTq0",
        "colab_type": "code",
        "outputId": "0b1b0eab-e590-4aba-d9ca-4175e2125c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"\\n\\n{0}: {1:.2f}%\".format(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 0s 72us/step\n",
            "\n",
            "\n",
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2ihtRTBQ9R",
        "colab_type": "text"
      },
      "source": [
        "Our accuracy across our test set is 96.67% meaning that if we were to use this model on new data from the same Iris dataset, it would correctly classify the Iris species 96.67% of the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnnHSuWHBmIT",
        "colab_type": "text"
      },
      "source": [
        "### The Confusion Matrix\n",
        "\n",
        "A confusion matrix is useful for describing the performance of a classification model. Instead of seeing generalised accuracy, we're able to look how each individual classification performs. \n",
        "\n",
        "In this case we can see that a sample of Versicolor was incorrectly classified as Virginica which we could try to improve in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEnF0buSzTq4",
        "colab_type": "code",
        "outputId": "0e09f871-e882-466c-b3f8-99d4df37f7a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "def draw_confusion_matrix(true, pred, labels):\n",
        "  \"\"\"\n",
        "  Drawing confusion matrix\n",
        "  \"\"\"\n",
        "  cm = metrics.confusion_matrix(true, pred, labels)\n",
        "  ax = plt.subplot()\n",
        "  sns.heatmap(cm, annot=True, ax=ax)\n",
        "  ax.set_xticklabels(['Setosa', 'Versicolor', 'Virginica']+labels)\n",
        "  ax.set_yticklabels(['Setosa', 'Versicolor', 'Virginica']+labels)\n",
        "  ax.set_xlabel(\"Predicted Classification\")\n",
        "  ax.set_ylabel(\"True Classification\")\n",
        "  plt.show()\n",
        "  return cm\n",
        "\n",
        "y_pred = model.predict_classes(X_test)\n",
        "y_test_encoded = [np.argmax(i) for i in y_test] # Reverse one hot encoded to label encoded\n",
        "matrix = draw_confusion_matrix(y_test_encoded, y_pred, [0,1,2]) #[setosa,versicolor, virginica]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNjMrKFfQZmYF5QrazKyg/j87nLaA4JTYlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhOFX6LUzTrD",
        "colab_type": "code",
        "outputId": "55151ca4-e825-43b1-84e1-a2f790f7f914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"acc: {0:.2f}%\".format(np.sum(np.diag(matrix))*100/np.sum(matrix)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHe0CcqcsO1Q",
        "colab_type": "text"
      },
      "source": [
        "# Key Points\n",
        "\n",
        "\n",
        "*   Created a neural network to solve multiclass classification problem\n",
        "*   \"One hot encoded\" to categorise string target variable\n",
        "*  Different loss functions for different classfication problems\n",
        "* Confusion matrix and model improvements\n",
        "\n",
        "\n"
      ]
    }
  ]
}