{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 2 - multi-class iris.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UoA-eResearch/deep-learning-tutorial-2019/blob/master/Exercise%202%20-%20multi-class%20iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPQTvjnTzTqM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2: The Iris Dataset\n",
        "In this exercise we will create a neural network to classify 3 different types of Iris (Setosa, Versicolor and Virginica) based on their sepal length, sepal width, petal length and petal width.\n",
        "\n",
        "![Irises](http://dataaspirant.com/wp-content/uploads/2017/01/irises.png)\n",
        "\n",
        "This is a multi class classification problem. It is similar to the Pima Indian's binary classification exercise, but with three classes to predict instead of two.\n",
        "\n",
        "### Q: Is this a supervised learning problem or unsupervised learning problem?\n",
        "\n",
        "*answer...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x9VrMNin1Yi",
        "colab_type": "text"
      },
      "source": [
        "### Q: How many steps are there in creating a neural network model? Please list those steps\n",
        "\n",
        "*answer...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B9pUqCzTqO",
        "colab_type": "text"
      },
      "source": [
        "### Import dependencies\n",
        "Start by importing the dependencies we will need for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB8CJHppzTqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcA6fnZKzTqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_acc_loss(history):\n",
        "    f, (ax1, ax2) = plt.subplots(2,1, figsize=(10,10))\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax1.plot(history.history['loss'])\n",
        "    ax1.plot(history.history['val_loss'])\n",
        "    ax1.set_title('model loss')\n",
        "    ax1.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax2.plot(history.history['acc'])\n",
        "    ax2.plot(history.history['val_acc'])\n",
        "    ax2.set_title('model accuracy')\n",
        "    ax2.set_xlabel('epoch')\n",
        "    ax2.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuDTA3s9zTqV",
        "colab_type": "text"
      },
      "source": [
        "### Set seed\n",
        "Set a seed value so that when we repeatedly run our code we will get the same result. Using the same seed is important when you want to compare algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeLiwmMNzTqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxNqXnJTzTqY",
        "colab_type": "text"
      },
      "source": [
        "### Import data\n",
        "The Iris dataset contains four features from 150 different Iris flowers. The features in the dataset are described below.\n",
        "\n",
        "* Sepal length (cm)\n",
        "* Sepal width (cm)\n",
        "* Petal length (cm)\n",
        "* Petal width (cm)\n",
        "* Class: Iris setosa, Iris versicolor or Iris virginica\n",
        "\n",
        "Sepals are the part of a flower that protect and support the petals. The petals surround the reproductive parts of the flower.\n",
        "\n",
        "![Iris labeled](http://terpconnect.umd.edu/~petersd/666/html/iris_with_labels.jpg)\n",
        "\n",
        "A snapshot of the dataset is illustrated below (not in order).\n",
        "\n",
        "|Sepal Length|Sepal Width|Petal Length|Petal Width|Class|\n",
        "|---|---|---|---|-----------|\n",
        "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
        "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
        "|7.0|3.2|4.7|1.4|Iris-versicolor|\n",
        "|6.4|3.2|4.5|1.5|Iris-versicolor|\n",
        "|6.3|3.3|6.0|2.5|Iris-virginica|\n",
        "|5.8|2.7|5.1|1.9|Iris-virginica|\n",
        "\n",
        "To load this data into memory, use the `np.loadtxt` function. The data type (`dtype`) is set to `str` because our input data is a mix of numbers and strings. This will be dealt with when we split the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wYz6SEDzTqY",
        "colab_type": "code",
        "outputId": "7626ee69-690d-44a9-f87f-9fb4e73999ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data = np.loadtxt('https://raw.githubusercontent.com/UoA-eResearch/deep-learning-tutorial-2019/master/data/iris.csv', delimiter=\",\", dtype=str)\n",
        "print(data[:6]) #Show the first 6 rows"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['5.1' '3.5' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.9' '3.0' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.7' '3.2' '1.3' '0.2' 'Iris-setosa']\n",
            " ['4.6' '3.1' '1.5' '0.2' 'Iris-setosa']\n",
            " ['5.0' '3.6' '1.4' '0.2' 'Iris-setosa']\n",
            " ['5.4' '3.9' '1.7' '0.4' 'Iris-setosa']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGLO13AQzTqb",
        "colab_type": "text"
      },
      "source": [
        "Separate the data into input (X) and output (y) variables.\n",
        "\n",
        "Note that we convert the input data into floats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-EcR4awzTqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[:, 0:4].astype(float)\n",
        "y = data[:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zYDMAbzTqd",
        "colab_type": "text"
      },
      "source": [
        "If you look carefully at the target values, you will notice that they are strings, i.e. 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'.\n",
        "\n",
        "**Keras needs numbers or matrices to work with, so we will need to reformat the target values.**\n",
        "\n",
        "The problem with converting the class values to numbers (e.g. 'Iris-setosa' becomes 0, 'Iris-versicolor' 1 etc) is that it implies that the target values are ordinal. That is, 'Iris-setosa' is somehow less than 'Iris-versicolor', which is not the case for this dataset.\n",
        "\n",
        "A better way to represent classes in a multi-class classification problem, is to 'one hot encode' the target values. An example is shown below. A matrix of zeros is generated. Each row corresponds to a sample and each column corresponds to a particular class. A 1 is placed into the column to incidicate the class that it belongs too.\n",
        "\n",
        "|Iris-setosa|Iris-versicolor|Iris-virginica|\n",
        "|---|---|---|\n",
        "|1|0|0|\n",
        "|0|1|0|\n",
        "|0|0|1|\n",
        "\n",
        "One hot encoding is a two step process. First encode the target values (y) into an array of numbers using the `LabelEncoder` from scikit-learn and then one hot encode the numbers with the `np_utils.to_categorical` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmReXRywzTqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa6780ba-08ed-453e-ef61-29edd81aac24"
      },
      "source": [
        "y_encoded = LabelEncoder().fit(y).transform(y) # Convert the classes into numbers\n",
        "y_encoded[45:55]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQgfvZcfzTqi",
        "colab_type": "code",
        "outputId": "fb732ad9-6fbe-4919-8d98-6943cbb7739e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_one_hot_encoded = np_utils.to_categorical(y_encoded) # One hot encode the numbers\n",
        "y_one_hot_encoded[45:55]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9s47Jx9zTqk",
        "colab_type": "text"
      },
      "source": [
        "Like the previous exercise, use the `train_test_split` function from scikit-learn to split the input and target data into training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qdeRm6LzTql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_encoded, test_size=0.33, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gp1FcnQzTqn",
        "colab_type": "text"
      },
      "source": [
        "### Create the model\n",
        "The code snippet below creates a very basic neural network model, with three layers: an input layer, a hidden layer and an output layer.\n",
        "\n",
        "The first layer is a fully connected `Dense` layer. We use four neurons in the hidden layer and have 4 input neurons for the 4 features.\n",
        "\n",
        "The last layer has 3 neurons, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG9oXx6dzTqn",
        "colab_type": "code",
        "outputId": "b5a95fd5-50ea-454f-bb4a-84d49e8454d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=4, activation='relu', kernel_initializer='normal'))\n",
        "model.add(Dense(3, activation='sigmoid', kernel_initializer='normal'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McwgpeyfzTqp",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "We then compile the model. The loss function is set to `categorical_crossentropy` (different from the loss function used in the binary classification exercise) because we are performing multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F86R20yJzTqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr-3q6CEzTqs",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "Now that we have compiled the model, we can train it with the data we prepared earlier. We are using more epochs but a smaller batch size than the previous exercise.\n",
        "\n",
        "To see the model training history in text, just don't include `verbose=0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ohIS-DzTqs",
        "colab_type": "code",
        "outputId": "b0f9995f-e12b-4003-e5d5-20cd41371f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6905
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 100 samples, validate on 50 samples\n",
            "Epoch 1/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.0999 - acc: 0.3600 - val_loss: 1.0989 - val_acc: 0.2800\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 0s 322us/step - loss: 1.0974 - acc: 0.5400 - val_loss: 1.0968 - val_acc: 0.6400\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 0s 316us/step - loss: 1.0952 - acc: 0.6800 - val_loss: 1.0942 - val_acc: 0.6400\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 0s 311us/step - loss: 1.0925 - acc: 0.6800 - val_loss: 1.0906 - val_acc: 0.6400\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 0s 323us/step - loss: 1.0886 - acc: 0.6600 - val_loss: 1.0855 - val_acc: 0.6400\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 0s 324us/step - loss: 1.0835 - acc: 0.6800 - val_loss: 1.0796 - val_acc: 0.6400\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 0s 298us/step - loss: 1.0762 - acc: 0.6800 - val_loss: 1.0720 - val_acc: 0.6400\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 0s 385us/step - loss: 1.0668 - acc: 0.6800 - val_loss: 1.0616 - val_acc: 0.6400\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 0s 351us/step - loss: 1.0553 - acc: 0.6800 - val_loss: 1.0495 - val_acc: 0.6400\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 0s 333us/step - loss: 1.0420 - acc: 0.6800 - val_loss: 1.0354 - val_acc: 0.6400\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 0s 332us/step - loss: 1.0257 - acc: 0.6800 - val_loss: 1.0188 - val_acc: 0.6400\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 0s 322us/step - loss: 1.0082 - acc: 0.6800 - val_loss: 1.0015 - val_acc: 0.6400\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 0s 337us/step - loss: 0.9886 - acc: 0.6800 - val_loss: 0.9818 - val_acc: 0.6400\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 0s 308us/step - loss: 0.9673 - acc: 0.6800 - val_loss: 0.9612 - val_acc: 0.6400\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 0s 293us/step - loss: 0.9451 - acc: 0.6800 - val_loss: 0.9397 - val_acc: 0.6400\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 0s 286us/step - loss: 0.9210 - acc: 0.6800 - val_loss: 0.9169 - val_acc: 0.6400\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.8987 - acc: 0.6800 - val_loss: 0.8961 - val_acc: 0.6400\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 0s 314us/step - loss: 0.8730 - acc: 0.6800 - val_loss: 0.8718 - val_acc: 0.6400\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.8495 - acc: 0.6800 - val_loss: 0.8496 - val_acc: 0.6400\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.8252 - acc: 0.6800 - val_loss: 0.8283 - val_acc: 0.6400\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.8016 - acc: 0.6800 - val_loss: 0.8074 - val_acc: 0.6400\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.7781 - acc: 0.6800 - val_loss: 0.7859 - val_acc: 0.6400\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.7549 - acc: 0.6800 - val_loss: 0.7649 - val_acc: 0.6400\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.7336 - acc: 0.6800 - val_loss: 0.7460 - val_acc: 0.6400\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 0s 293us/step - loss: 0.7123 - acc: 0.6900 - val_loss: 0.7270 - val_acc: 0.6400\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 0s 307us/step - loss: 0.6919 - acc: 0.6900 - val_loss: 0.7094 - val_acc: 0.6400\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 0s 288us/step - loss: 0.6729 - acc: 0.6900 - val_loss: 0.6925 - val_acc: 0.6600\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 0s 323us/step - loss: 0.6550 - acc: 0.6900 - val_loss: 0.6756 - val_acc: 0.6600\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 0.6380 - acc: 0.7100 - val_loss: 0.6618 - val_acc: 0.6600\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.6197 - acc: 0.7300 - val_loss: 0.6456 - val_acc: 0.6600\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.6051 - acc: 0.7300 - val_loss: 0.6320 - val_acc: 0.6600\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.5890 - acc: 0.7500 - val_loss: 0.6178 - val_acc: 0.7400\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 0s 312us/step - loss: 0.5746 - acc: 0.7900 - val_loss: 0.6045 - val_acc: 0.8200\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 0s 324us/step - loss: 0.5609 - acc: 0.8500 - val_loss: 0.5920 - val_acc: 0.8600\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.5483 - acc: 0.8900 - val_loss: 0.5795 - val_acc: 0.8600\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.5358 - acc: 0.9000 - val_loss: 0.5688 - val_acc: 0.9200\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.5245 - acc: 0.9700 - val_loss: 0.5577 - val_acc: 0.9600\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.5132 - acc: 0.9700 - val_loss: 0.5478 - val_acc: 0.9600\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.5028 - acc: 0.9700 - val_loss: 0.5381 - val_acc: 0.9600\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.4926 - acc: 0.9700 - val_loss: 0.5286 - val_acc: 0.9600\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.4839 - acc: 0.9700 - val_loss: 0.5199 - val_acc: 0.9800\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.4740 - acc: 0.9700 - val_loss: 0.5115 - val_acc: 0.9600\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 0s 275us/step - loss: 0.4666 - acc: 0.9700 - val_loss: 0.5037 - val_acc: 0.9600\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.4587 - acc: 0.9600 - val_loss: 0.4953 - val_acc: 1.0000\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.4487 - acc: 0.9700 - val_loss: 0.4874 - val_acc: 0.9800\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.4428 - acc: 0.9700 - val_loss: 0.4804 - val_acc: 0.9600\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.4332 - acc: 0.9700 - val_loss: 0.4726 - val_acc: 0.9800\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.4257 - acc: 0.9700 - val_loss: 0.4658 - val_acc: 0.9800\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.4199 - acc: 0.9600 - val_loss: 0.4588 - val_acc: 0.9800\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 0s 268us/step - loss: 0.4134 - acc: 0.9700 - val_loss: 0.4527 - val_acc: 0.9600\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.4090 - acc: 0.9700 - val_loss: 0.4462 - val_acc: 1.0000\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.4017 - acc: 0.9700 - val_loss: 0.4395 - val_acc: 0.9600\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.3940 - acc: 0.9700 - val_loss: 0.4333 - val_acc: 0.9800\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.3861 - acc: 0.9700 - val_loss: 0.4277 - val_acc: 0.9800\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.3825 - acc: 0.9700 - val_loss: 0.4222 - val_acc: 1.0000\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.3747 - acc: 0.9700 - val_loss: 0.4167 - val_acc: 0.9600\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.3699 - acc: 0.9700 - val_loss: 0.4110 - val_acc: 0.9600\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.3638 - acc: 0.9700 - val_loss: 0.4059 - val_acc: 0.9800\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 0s 275us/step - loss: 0.3605 - acc: 0.9600 - val_loss: 0.4006 - val_acc: 1.0000\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 0s 303us/step - loss: 0.3557 - acc: 0.9700 - val_loss: 0.3961 - val_acc: 0.9600\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 0s 333us/step - loss: 0.3493 - acc: 0.9700 - val_loss: 0.3906 - val_acc: 0.9800\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 0s 283us/step - loss: 0.3439 - acc: 0.9700 - val_loss: 0.3856 - val_acc: 0.9800\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 0s 279us/step - loss: 0.3419 - acc: 0.9700 - val_loss: 0.3814 - val_acc: 0.9800\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.3359 - acc: 0.9700 - val_loss: 0.3772 - val_acc: 0.9800\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.3305 - acc: 0.9700 - val_loss: 0.3723 - val_acc: 0.9800\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.3262 - acc: 0.9700 - val_loss: 0.3681 - val_acc: 0.9800\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.3218 - acc: 0.9700 - val_loss: 0.3637 - val_acc: 0.9800\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 0.3185 - acc: 0.9700 - val_loss: 0.3601 - val_acc: 0.9600\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 0s 275us/step - loss: 0.3150 - acc: 0.9700 - val_loss: 0.3556 - val_acc: 0.9800\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 0s 288us/step - loss: 0.3099 - acc: 0.9700 - val_loss: 0.3520 - val_acc: 0.9800\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.3066 - acc: 0.9700 - val_loss: 0.3481 - val_acc: 0.9800\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.3041 - acc: 0.9700 - val_loss: 0.3444 - val_acc: 0.9800\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.2994 - acc: 0.9700 - val_loss: 0.3413 - val_acc: 1.0000\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 0s 292us/step - loss: 0.2978 - acc: 0.9700 - val_loss: 0.3373 - val_acc: 0.9800\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.2938 - acc: 0.9700 - val_loss: 0.3345 - val_acc: 0.9600\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.2908 - acc: 0.9700 - val_loss: 0.3305 - val_acc: 0.9800\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.2862 - acc: 0.9700 - val_loss: 0.3273 - val_acc: 0.9800\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 0s 280us/step - loss: 0.2843 - acc: 0.9700 - val_loss: 0.3242 - val_acc: 0.9800\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 0s 300us/step - loss: 0.2816 - acc: 0.9700 - val_loss: 0.3221 - val_acc: 1.0000\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 0s 278us/step - loss: 0.2771 - acc: 0.9700 - val_loss: 0.3179 - val_acc: 0.9800\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.2748 - acc: 0.9700 - val_loss: 0.3148 - val_acc: 0.9800\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.2707 - acc: 0.9700 - val_loss: 0.3120 - val_acc: 0.9800\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.2694 - acc: 0.9600 - val_loss: 0.3101 - val_acc: 1.0000\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.2654 - acc: 0.9700 - val_loss: 0.3064 - val_acc: 0.9800\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 0s 268us/step - loss: 0.2643 - acc: 0.9700 - val_loss: 0.3034 - val_acc: 0.9800\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.2612 - acc: 0.9700 - val_loss: 0.3006 - val_acc: 0.9800\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.2578 - acc: 0.9700 - val_loss: 0.2980 - val_acc: 0.9800\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 0s 241us/step - loss: 0.2557 - acc: 0.9600 - val_loss: 0.2958 - val_acc: 1.0000\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 0s 301us/step - loss: 0.2529 - acc: 0.9700 - val_loss: 0.2924 - val_acc: 0.9800\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.2505 - acc: 0.9700 - val_loss: 0.2904 - val_acc: 0.9800\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 0s 311us/step - loss: 0.2494 - acc: 0.9700 - val_loss: 0.2876 - val_acc: 0.9800\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.2459 - acc: 0.9700 - val_loss: 0.2850 - val_acc: 0.9800\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.2436 - acc: 0.9600 - val_loss: 0.2831 - val_acc: 1.0000\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.2408 - acc: 0.9600 - val_loss: 0.2802 - val_acc: 0.9800\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.2399 - acc: 0.9700 - val_loss: 0.2777 - val_acc: 0.9800\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.2366 - acc: 0.9600 - val_loss: 0.2761 - val_acc: 0.9800\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.2346 - acc: 0.9600 - val_loss: 0.2734 - val_acc: 0.9800\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 0s 289us/step - loss: 0.2337 - acc: 0.9700 - val_loss: 0.2708 - val_acc: 0.9800\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.2301 - acc: 0.9700 - val_loss: 0.2691 - val_acc: 0.9800\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 0s 289us/step - loss: 0.2291 - acc: 0.9600 - val_loss: 0.2668 - val_acc: 0.9800\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 0s 298us/step - loss: 0.2273 - acc: 0.9700 - val_loss: 0.2645 - val_acc: 0.9800\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.2257 - acc: 0.9600 - val_loss: 0.2625 - val_acc: 0.9800\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.2224 - acc: 0.9600 - val_loss: 0.2620 - val_acc: 1.0000\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.2210 - acc: 0.9600 - val_loss: 0.2585 - val_acc: 0.9800\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.2187 - acc: 0.9700 - val_loss: 0.2564 - val_acc: 0.9800\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.2167 - acc: 0.9700 - val_loss: 0.2549 - val_acc: 0.9800\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.2155 - acc: 0.9600 - val_loss: 0.2535 - val_acc: 1.0000\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.2136 - acc: 0.9700 - val_loss: 0.2507 - val_acc: 0.9800\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.2133 - acc: 0.9600 - val_loss: 0.2488 - val_acc: 0.9800\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 0s 300us/step - loss: 0.2109 - acc: 0.9700 - val_loss: 0.2473 - val_acc: 0.9800\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.2088 - acc: 0.9700 - val_loss: 0.2461 - val_acc: 1.0000\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 0s 283us/step - loss: 0.2079 - acc: 0.9700 - val_loss: 0.2441 - val_acc: 0.9800\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.2083 - acc: 0.9600 - val_loss: 0.2418 - val_acc: 0.9800\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 0s 317us/step - loss: 0.2033 - acc: 0.9700 - val_loss: 0.2408 - val_acc: 0.9800\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.2027 - acc: 0.9700 - val_loss: 0.2390 - val_acc: 0.9800\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.2005 - acc: 0.9700 - val_loss: 0.2372 - val_acc: 0.9800\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.2010 - acc: 0.9700 - val_loss: 0.2354 - val_acc: 0.9800\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.2031 - acc: 0.9700 - val_loss: 0.2364 - val_acc: 1.0000\n",
            "Epoch 119/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1991 - acc: 0.9700 - val_loss: 0.2325 - val_acc: 0.9800\n",
            "Epoch 120/200\n",
            "100/100 [==============================] - 0s 318us/step - loss: 0.1966 - acc: 0.9600 - val_loss: 0.2320 - val_acc: 1.0000\n",
            "Epoch 121/200\n",
            "100/100 [==============================] - 0s 294us/step - loss: 0.1934 - acc: 0.9700 - val_loss: 0.2292 - val_acc: 0.9800\n",
            "Epoch 122/200\n",
            "100/100 [==============================] - 0s 282us/step - loss: 0.1922 - acc: 0.9700 - val_loss: 0.2277 - val_acc: 0.9800\n",
            "Epoch 123/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.1913 - acc: 0.9600 - val_loss: 0.2270 - val_acc: 0.9800\n",
            "Epoch 124/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.1895 - acc: 0.9600 - val_loss: 0.2248 - val_acc: 0.9800\n",
            "Epoch 125/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.1887 - acc: 0.9700 - val_loss: 0.2238 - val_acc: 0.9800\n",
            "Epoch 126/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1875 - acc: 0.9600 - val_loss: 0.2221 - val_acc: 0.9800\n",
            "Epoch 127/200\n",
            "100/100 [==============================] - 0s 287us/step - loss: 0.1856 - acc: 0.9600 - val_loss: 0.2219 - val_acc: 1.0000\n",
            "Epoch 128/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1868 - acc: 0.9800 - val_loss: 0.2208 - val_acc: 1.0000\n",
            "Epoch 129/200\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.1835 - acc: 0.9700 - val_loss: 0.2179 - val_acc: 0.9800\n",
            "Epoch 130/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.1849 - acc: 0.9600 - val_loss: 0.2172 - val_acc: 0.9800\n",
            "Epoch 131/200\n",
            "100/100 [==============================] - 0s 282us/step - loss: 0.1829 - acc: 0.9600 - val_loss: 0.2153 - val_acc: 0.9800\n",
            "Epoch 132/200\n",
            "100/100 [==============================] - 0s 320us/step - loss: 0.1812 - acc: 0.9700 - val_loss: 0.2143 - val_acc: 0.9800\n",
            "Epoch 133/200\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.1820 - acc: 0.9900 - val_loss: 0.2156 - val_acc: 1.0000\n",
            "Epoch 134/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1771 - acc: 0.9700 - val_loss: 0.2126 - val_acc: 1.0000\n",
            "Epoch 135/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.1765 - acc: 0.9600 - val_loss: 0.2106 - val_acc: 0.9800\n",
            "Epoch 136/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1754 - acc: 0.9600 - val_loss: 0.2093 - val_acc: 0.9800\n",
            "Epoch 137/200\n",
            "100/100 [==============================] - 0s 306us/step - loss: 0.1747 - acc: 0.9700 - val_loss: 0.2081 - val_acc: 0.9800\n",
            "Epoch 138/200\n",
            "100/100 [==============================] - 0s 327us/step - loss: 0.1733 - acc: 0.9600 - val_loss: 0.2076 - val_acc: 0.9800\n",
            "Epoch 139/200\n",
            "100/100 [==============================] - 0s 279us/step - loss: 0.1723 - acc: 0.9600 - val_loss: 0.2067 - val_acc: 0.9800\n",
            "Epoch 140/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.1723 - acc: 0.9600 - val_loss: 0.2045 - val_acc: 0.9800\n",
            "Epoch 141/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.1696 - acc: 0.9700 - val_loss: 0.2043 - val_acc: 0.9800\n",
            "Epoch 142/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.1693 - acc: 0.9600 - val_loss: 0.2036 - val_acc: 1.0000\n",
            "Epoch 143/200\n",
            "100/100 [==============================] - 0s 268us/step - loss: 0.1688 - acc: 0.9700 - val_loss: 0.2030 - val_acc: 1.0000\n",
            "Epoch 144/200\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.1692 - acc: 0.9600 - val_loss: 0.2001 - val_acc: 0.9800\n",
            "Epoch 145/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.1658 - acc: 0.9700 - val_loss: 0.1995 - val_acc: 0.9800\n",
            "Epoch 146/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.1656 - acc: 0.9700 - val_loss: 0.1995 - val_acc: 1.0000\n",
            "Epoch 147/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.1654 - acc: 0.9600 - val_loss: 0.1980 - val_acc: 0.9800\n",
            "Epoch 148/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1638 - acc: 0.9600 - val_loss: 0.1963 - val_acc: 0.9800\n",
            "Epoch 149/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1628 - acc: 0.9600 - val_loss: 0.1960 - val_acc: 0.9800\n",
            "Epoch 150/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.1630 - acc: 0.9700 - val_loss: 0.1957 - val_acc: 1.0000\n",
            "Epoch 151/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1609 - acc: 0.9700 - val_loss: 0.1931 - val_acc: 0.9800\n",
            "Epoch 152/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.1629 - acc: 0.9700 - val_loss: 0.1940 - val_acc: 1.0000\n",
            "Epoch 153/200\n",
            "100/100 [==============================] - 0s 292us/step - loss: 0.1591 - acc: 0.9800 - val_loss: 0.1912 - val_acc: 0.9800\n",
            "Epoch 154/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.1586 - acc: 0.9600 - val_loss: 0.1909 - val_acc: 0.9800\n",
            "Epoch 155/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.1573 - acc: 0.9600 - val_loss: 0.1901 - val_acc: 0.9800\n",
            "Epoch 156/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1563 - acc: 0.9700 - val_loss: 0.1892 - val_acc: 0.9800\n",
            "Epoch 157/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.1576 - acc: 0.9600 - val_loss: 0.1876 - val_acc: 0.9800\n",
            "Epoch 158/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1555 - acc: 0.9600 - val_loss: 0.1885 - val_acc: 1.0000\n",
            "Epoch 159/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.1546 - acc: 0.9700 - val_loss: 0.1869 - val_acc: 1.0000\n",
            "Epoch 160/200\n",
            "100/100 [==============================] - 0s 279us/step - loss: 0.1544 - acc: 0.9700 - val_loss: 0.1847 - val_acc: 0.9800\n",
            "Epoch 161/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.1527 - acc: 0.9700 - val_loss: 0.1849 - val_acc: 0.9800\n",
            "Epoch 162/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1524 - acc: 0.9600 - val_loss: 0.1838 - val_acc: 0.9800\n",
            "Epoch 163/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.1516 - acc: 0.9600 - val_loss: 0.1827 - val_acc: 0.9800\n",
            "Epoch 164/200\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.1503 - acc: 0.9600 - val_loss: 0.1819 - val_acc: 0.9800\n",
            "Epoch 165/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1493 - acc: 0.9600 - val_loss: 0.1807 - val_acc: 0.9800\n",
            "Epoch 166/200\n",
            "100/100 [==============================] - 0s 295us/step - loss: 0.1493 - acc: 0.9700 - val_loss: 0.1813 - val_acc: 1.0000\n",
            "Epoch 167/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.1481 - acc: 0.9600 - val_loss: 0.1788 - val_acc: 0.9800\n",
            "Epoch 168/200\n",
            "100/100 [==============================] - 0s 300us/step - loss: 0.1483 - acc: 0.9600 - val_loss: 0.1791 - val_acc: 0.9800\n",
            "Epoch 169/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 0.1465 - acc: 0.9700 - val_loss: 0.1776 - val_acc: 0.9800\n",
            "Epoch 170/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.1461 - acc: 0.9600 - val_loss: 0.1768 - val_acc: 0.9800\n",
            "Epoch 171/200\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.1453 - acc: 0.9600 - val_loss: 0.1757 - val_acc: 0.9800\n",
            "Epoch 172/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.1462 - acc: 0.9700 - val_loss: 0.1761 - val_acc: 0.9800\n",
            "Epoch 173/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.1435 - acc: 0.9600 - val_loss: 0.1747 - val_acc: 0.9800\n",
            "Epoch 174/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.1433 - acc: 0.9600 - val_loss: 0.1736 - val_acc: 0.9800\n",
            "Epoch 175/200\n",
            "100/100 [==============================] - 0s 285us/step - loss: 0.1422 - acc: 0.9600 - val_loss: 0.1730 - val_acc: 0.9800\n",
            "Epoch 176/200\n",
            "100/100 [==============================] - 0s 322us/step - loss: 0.1422 - acc: 0.9600 - val_loss: 0.1720 - val_acc: 0.9800\n",
            "Epoch 177/200\n",
            "100/100 [==============================] - 0s 235us/step - loss: 0.1421 - acc: 0.9700 - val_loss: 0.1723 - val_acc: 0.9800\n",
            "Epoch 178/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1423 - acc: 0.9700 - val_loss: 0.1733 - val_acc: 1.0000\n",
            "Epoch 179/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.1403 - acc: 0.9600 - val_loss: 0.1698 - val_acc: 0.9800\n",
            "Epoch 180/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.1402 - acc: 0.9600 - val_loss: 0.1692 - val_acc: 0.9800\n",
            "Epoch 181/200\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.1394 - acc: 0.9600 - val_loss: 0.1686 - val_acc: 0.9800\n",
            "Epoch 182/200\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.1382 - acc: 0.9700 - val_loss: 0.1687 - val_acc: 0.9800\n",
            "Epoch 183/200\n",
            "100/100 [==============================] - 0s 313us/step - loss: 0.1377 - acc: 0.9700 - val_loss: 0.1684 - val_acc: 0.9800\n",
            "Epoch 184/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.1370 - acc: 0.9600 - val_loss: 0.1672 - val_acc: 0.9800\n",
            "Epoch 185/200\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.1360 - acc: 0.9700 - val_loss: 0.1666 - val_acc: 0.9800\n",
            "Epoch 186/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1357 - acc: 0.9600 - val_loss: 0.1657 - val_acc: 0.9800\n",
            "Epoch 187/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.1353 - acc: 0.9700 - val_loss: 0.1647 - val_acc: 0.9800\n",
            "Epoch 188/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.1344 - acc: 0.9600 - val_loss: 0.1643 - val_acc: 0.9800\n",
            "Epoch 189/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.1375 - acc: 0.9700 - val_loss: 0.1644 - val_acc: 0.9800\n",
            "Epoch 190/200\n",
            "100/100 [==============================] - 0s 297us/step - loss: 0.1327 - acc: 0.9700 - val_loss: 0.1631 - val_acc: 0.9800\n",
            "Epoch 191/200\n",
            "100/100 [==============================] - 0s 347us/step - loss: 0.1328 - acc: 0.9600 - val_loss: 0.1620 - val_acc: 0.9800\n",
            "Epoch 192/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1324 - acc: 0.9600 - val_loss: 0.1618 - val_acc: 0.9800\n",
            "Epoch 193/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1325 - acc: 0.9600 - val_loss: 0.1613 - val_acc: 0.9800\n",
            "Epoch 194/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.1317 - acc: 0.9700 - val_loss: 0.1607 - val_acc: 0.9800\n",
            "Epoch 195/200\n",
            "100/100 [==============================] - 0s 303us/step - loss: 0.1304 - acc: 0.9600 - val_loss: 0.1597 - val_acc: 0.9800\n",
            "Epoch 196/200\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.1306 - acc: 0.9600 - val_loss: 0.1593 - val_acc: 0.9800\n",
            "Epoch 197/200\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.1299 - acc: 0.9700 - val_loss: 0.1597 - val_acc: 0.9800\n",
            "Epoch 198/200\n",
            "100/100 [==============================] - 0s 287us/step - loss: 0.1291 - acc: 0.9700 - val_loss: 0.1579 - val_acc: 0.9800\n",
            "Epoch 199/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.1308 - acc: 0.9600 - val_loss: 0.1589 - val_acc: 1.0000\n",
            "Epoch 200/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1287 - acc: 0.9700 - val_loss: 0.1568 - val_acc: 0.9800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwYPK696zTqu",
        "colab_type": "code",
        "outputId": "3faecccf-79d7-4cb0-d5d7-5c02e5684ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plot_acc_loss(history)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJcCAYAAAA7Pup5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw2wWtw5zTqy",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model\n",
        "Now that we have trained our model, we can evaluate the performance on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQtZLcOdzTq0",
        "colab_type": "code",
        "outputId": "894f2bd5-c716-46f1-bb8b-fb160561acff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "scores = model.evaluate(X, y_one_hot_encoded)\n",
        "print(\"\\n\\n{0}: {1:.2f}%\".format(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 0s 44us/step\n",
            "\n",
            "\n",
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEnF0buSzTq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "536032ef-6786-47a5-96b4-5cc638448f79"
      },
      "source": [
        "y_pred = model.predict_classes(X)\n",
        "matrix = metrics.confusion_matrix(y_encoded, y_pred) # (y_true,y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[50  0  0]\n",
            " [ 0 46  4]\n",
            " [ 0  1 49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhOFX6LUzTrD",
        "colab_type": "code",
        "outputId": "408524c3-d008-4514-b80e-f56fc7ba3fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"acc: {0:.2f}%\".format(((50+46+49)/(50+46+49+1+4))*100))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}